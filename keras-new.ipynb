{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from scipy import stats\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Activation\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.convolutional import AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./input/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = len(data)\n",
    "X = np.array(data.loc[:, data.columns != 'label'])\n",
    "Y = np.array(data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (37800, 28, 28, 1), shape of y_train: (37800,)\n",
      "Shape of X_test: (4200, 28, 28, 1), shape of y_test: (4200,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train: {}, shape of y_train: {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Shape of X_test: {}, shape of y_test: {}\".format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3,3), input_shape=(28, 28, 1), activation='relu'))\n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "    model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/30\n",
      "37800/37800 [==============================] - 5s 131us/step - loss: 0.3145 - acc: 0.8989 - val_loss: 0.0829 - val_acc: 0.9745\n",
      "Epoch 2/30\n",
      "37800/37800 [==============================] - 3s 72us/step - loss: 0.0710 - acc: 0.9779 - val_loss: 0.0549 - val_acc: 0.9817\n",
      "Epoch 3/30\n",
      "37800/37800 [==============================] - 3s 72us/step - loss: 0.0475 - acc: 0.9847 - val_loss: 0.0448 - val_acc: 0.9855\n",
      "Epoch 4/30\n",
      "37800/37800 [==============================] - 3s 72us/step - loss: 0.0385 - acc: 0.9879 - val_loss: 0.0405 - val_acc: 0.9879\n",
      "Epoch 5/30\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.0280 - acc: 0.9905 - val_loss: 0.0383 - val_acc: 0.9886\n",
      "Epoch 6/30\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.0232 - acc: 0.9929 - val_loss: 0.0405 - val_acc: 0.9871\n",
      "Epoch 7/30\n",
      "37800/37800 [==============================] - 3s 72us/step - loss: 0.0183 - acc: 0.9945 - val_loss: 0.0347 - val_acc: 0.9890\n",
      "Epoch 8/30\n",
      "37800/37800 [==============================] - 3s 72us/step - loss: 0.0180 - acc: 0.9942 - val_loss: 0.0319 - val_acc: 0.9905\n",
      "Epoch 9/30\n",
      "37800/37800 [==============================] - 3s 72us/step - loss: 0.0151 - acc: 0.9947 - val_loss: 0.0326 - val_acc: 0.9895\n",
      "Epoch 10/30\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.0133 - acc: 0.9957 - val_loss: 0.0285 - val_acc: 0.9905\n",
      "Epoch 00010: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc5014c8828>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = cnn_model()\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30, batch_size=200, callbacks=[EarlyStopping(monitor='val_acc', min_delta=0.0001, patience=2, verbose=1, mode='auto')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet Error: 0.95%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"ConvNet Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3,3), input_shape=(28, 28, 1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32, (3,3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv2D(64, (3,3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, (3,3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/30\n",
      "37800/37800 [==============================] - 7s 192us/step - loss: 0.2340 - acc: 0.9276 - val_loss: 0.0621 - val_acc: 0.9817\n",
      "Epoch 2/30\n",
      "37800/37800 [==============================] - 5s 124us/step - loss: 0.0694 - acc: 0.9781 - val_loss: 0.0395 - val_acc: 0.9871\n",
      "Epoch 3/30\n",
      "37800/37800 [==============================] - 5s 124us/step - loss: 0.0547 - acc: 0.9833 - val_loss: 0.0390 - val_acc: 0.9862\n",
      "Epoch 4/30\n",
      "37800/37800 [==============================] - 5s 122us/step - loss: 0.0427 - acc: 0.9863 - val_loss: 0.0388 - val_acc: 0.9881\n",
      "Epoch 5/30\n",
      "37800/37800 [==============================] - 5s 123us/step - loss: 0.0357 - acc: 0.9888 - val_loss: 0.0306 - val_acc: 0.9907\n",
      "Epoch 6/30\n",
      "37800/37800 [==============================] - 5s 123us/step - loss: 0.0294 - acc: 0.9898 - val_loss: 0.0328 - val_acc: 0.9890\n",
      "Epoch 7/30\n",
      "37800/37800 [==============================] - 5s 123us/step - loss: 0.0284 - acc: 0.9904 - val_loss: 0.0401 - val_acc: 0.9888\n",
      "Epoch 00007: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc7e9c66b38>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = cnn_model()\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30, batch_size=200, callbacks=[EarlyStopping(monitor='val_acc', min_delta=1e-5, patience=2, verbose=1, mode='auto')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet Error: 1.12%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"ConvNet Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rotation_range=8, width_shift_range=0.05, shear_range=0.1, height_shift_range=0.05, zoom_range=0.05)\n",
    "test_datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=64)\n",
    "test_generator = test_datagen.flow(X_test, y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.2271 - acc: 0.9308 - val_loss: 0.0458 - val_acc: 0.9857\n",
      "Epoch 2/15\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0817 - acc: 0.9745 - val_loss: 0.0392 - val_acc: 0.9874\n",
      "Epoch 3/15\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0678 - acc: 0.9793 - val_loss: 0.0368 - val_acc: 0.9886\n",
      "Epoch 4/15\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0587 - acc: 0.9820 - val_loss: 0.0299 - val_acc: 0.9918\n",
      "Epoch 5/15\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0524 - acc: 0.9841 - val_loss: 0.0462 - val_acc: 0.9857\n",
      "Epoch 6/15\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0477 - acc: 0.9852 - val_loss: 0.0451 - val_acc: 0.9875\n",
      "Epoch 7/15\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0432 - acc: 0.9860 - val_loss: 0.0401 - val_acc: 0.9887\n",
      "Epoch 8/15\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0385 - acc: 0.9878 - val_loss: 0.0241 - val_acc: 0.9930\n",
      "Epoch 9/15\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0377 - acc: 0.9883 - val_loss: 0.1156 - val_acc: 0.9662\n",
      "Epoch 10/15\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0356 - acc: 0.9890 - val_loss: 0.0163 - val_acc: 0.9942\n",
      "Epoch 11/15\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0302 - acc: 0.9903 - val_loss: 0.0238 - val_acc: 0.9926\n",
      "Epoch 12/15\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0308 - acc: 0.9901 - val_loss: 0.0266 - val_acc: 0.9923\n",
      "Epoch 13/15\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0271 - acc: 0.9912 - val_loss: 0.0217 - val_acc: 0.9921\n",
      "Epoch 14/15\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0247 - acc: 0.9923 - val_loss: 0.0197 - val_acc: 0.9945\n",
      "Epoch 15/15\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 0.0277 - acc: 0.9919 - val_loss: 0.0137 - val_acc: 0.9964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc502cb1b38>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = cnn_model()\n",
    "model.fit_generator(train_generator, steps_per_epoch=64000//64, epochs=15, validation_data=test_generator, validation_steps=10000//64)#, callbacks=[EarlyStopping(monitor='val_acc', min_delta=1e-5, patience=2, verbose=1, mode='auto')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet Error: 0.38%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"ConvNet Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[420   0   0   0   0   0   1   0   1   0]\n",
      " [  0 472   0   0   0   0   1   0   0   0]\n",
      " [  1   0 408   0   0   0   0   0   0   0]\n",
      " [  0   0   0 425   0   0   0   1   0   0]\n",
      " [  0   0   0   0 427   0   1   0   0   1]\n",
      " [  0   0   0   0   0 381   1   0   0   0]\n",
      " [  0   0   0   0   1   0 411   0   0   0]\n",
      " [  0   1   1   1   0   0   0 466   0   0]\n",
      " [  0   1   0   0   0   1   0   0 382   0]\n",
      " [  0   0   0   0   1   0   0   0   1 392]]\n"
     ]
    }
   ],
   "source": [
    "Y_test_pred = model.predict_classes(X_test)\n",
    "Y_test_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(confusion_matrix(Y_test_true, Y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submfile(fname=\"subm.csv\"):\n",
    "    submdata = pd.read_csv(\"./input/test.csv\")\n",
    "    m = len(submdata)\n",
    "    X_subm = np.array(submdata)\n",
    "    X_subm = X_subm.reshape(m, 28, 28, 1).astype('float32')\n",
    "    X_subm /= 255\n",
    "    pred = model.predict(X_subm)\n",
    "    subm = pd.DataFrame({\"ImageId\": np.arange(1, m+1), \"Label\": np.argmax(pred, axis=1)})\n",
    "    subm.to_csv(fname, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "submfile(\"subm8.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "submdata = pd.read_csv(\"./input/test.csv\")\n",
    "m = len(submdata)\n",
    "X_subm = np.array(submdata)\n",
    "X_subm = X_subm.reshape(m, 28, 28, 1).astype('float32')\n",
    "X_subm /= 255\n",
    "pred = model.predict(X_subm)\n",
    "subm = pd.DataFrame({\"ImageId\": np.arange(1, m+1), \"Label\": np.argmax(pred, axis=1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADp9JREFUeJzt3X2MVfWdx/HPl3EGCugqCiwCFVSsT7uCmcVNaYxbH0q1DTSNVtK0tHE73a6abdbNrjHZaPqwce1a2xjXigWLjaKtitKUWA0xxaYtcSTGp5GH0qmOEIaKWWDd8jDz3T/mTDPi3N+93HvOPRe+71dC5t7zPeeeby7zmXPv/Z1zf+buAhDPmLIbAFAOwg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+IKjjmrmzDhvr4zShmbsEQvmT/lcHfL/Vsm5D4TezhZK+L6lN0g/d/fbU+uM0QRfZpY3sEkDCBl9X87p1v+w3szZJ90j6pKRzJS0xs3PrfTwAzdXIe/75kra6+zZ3PyDpEUmL8mkLQNEaCf90SW+NuN+XLXsfM+sys24z6z6o/Q3sDkCeGgn/aB8qfOD6YHdf5u6d7t7ZrrEN7A5AnhoJf5+kmSPuz5C0vbF2ADRLI+F/QdIcM5ttZh2SrpW0Jp+2ABSt7qE+dz9kZjdI+oWGhvpWuPtruXUGoFANjfO7+1pJa3PqBUATcXovEBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0E1dYpuxGNjK8/SNOa0GcltBzb/Lu92MAJHfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IqqFxfjPrlbRX0oCkQ+7emUdTOHq0nXVGsj71wf6KtXtmrEpu+4kbb0zWx6/ekKwjLY+TfP7O3f+Yw+MAaCJe9gNBNRp+l/SMmb1oZl15NASgORp92b/A3beb2RRJz5rZG+6+fuQK2R+FLkkap/EN7g5AXho68rv79uxnv6TVkuaPss4yd+909852Vb7IA0Bz1R1+M5tgZscP35Z0haRX82oMQLEaedk/VdJqMxt+nIfd/elcugJQuLrD7+7bJF2QYy8owZjzz07W37j+hGT9Wx9/PFm/duKuRDX96/fOeW3J+vjVyTKqYKgPCIrwA0ERfiAowg8ERfiBoAg/EBRf3X0MOG76qRVrm+6Ymtz2iQX3JuvntXfU1VMenu66I1n/h59+KVkf2LQ1x26OPRz5gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAoxvmPAe0PD1SsbTpzeZWtix3H/+m+kyvWrp74TnLb6W3pr33b+uXJyfrsmxnnT+HIDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBMc5/DLj45C2FPfbP35uYrH/7G0uT9ZN69lasffSJHyS3rTbOj8Zw5AeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoKqO85vZCkmfktTv7udnyyZJelTSLEm9kq5x93eLaxMpq+78RMXamiV/ndz27Y3TkvWz7tuerJ/4+98k65p3XsVSe3pLFKyWI/+PJC08bNnNkta5+xxJ67L7AI4iVcPv7usl7T5s8SJJK7PbKyUtzrkvAAWr9z3/VHffIUnZzyn5tQSgGQo/t9/MuiR1SdI4ca420CrqPfLvNLNpkpT97K+0orsvc/dOd+9s19g6dwcgb/WGf42k4cu5lkp6Kp92ADRL1fCb2SpJv5H0ETPrM7PrJN0u6XIz2yLp8uw+gKNI1ff87r6kQunSnHtBnSY9kBhrfyC97enqTdYPHXk77zP4ocq/YlO4Xr9UnOEHBEX4gaAIPxAU4QeCIvxAUIQfCIqv7kahTvnOm4U9dse7VthjR8CRHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCYpw/B22TJyfrNjF96eq2L05P1mff9WqyPrBnT7JeJBub/namfz316UQ1/eXd+3x/sn7aI28l641ejnys48gPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0Exzp8Zc/zxyfqme+ZUrPVcel9y2+PUVldPwz532RXJ+nuLJ1WsDbxz+ByrR6baOP6ux05L1v+qo/6JuOev/OdkfdYfqkwP3oC2E/8iWbcJE5L1Q2+npzZvBRz5gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiCoquP8ZrZC0qck9bv7+dmy2yR9RdKubLVb3H1tUU3mYcwF5yTrX3vsqWT9qvG/TFTT4/hXbfp0sv6PM59L1h89/ZlkfclTl1es7VtU+RwASfIDB5P1zd84L12/8L+T9ZTfpi/X1+zVe5N1r3vP1fX851nJ+qRT/ydZPyX9X94Sajny/0jSwlGW3+Xuc7N/LR18AB9UNfzuvl5SY6eJAWg5jbznv8HMXjazFWZ2Um4dAWiKesN/r6QzJM2VtEPSnZVWNLMuM+s2s+6DqvImD0DT1BV+d9/p7gPuPijpfknzE+suc/dOd+9sV/oiEQDNU1f4zWzaiLufkZT+elkALaeWob5Vki6RdIqZ9Um6VdIlZjZXQ6MtvZK+WmCPAApQNfzuvmSUxcsL6KVQb9yYvv76qvH76n7sy65L/+0b9/zryfp9J1ycrL/8i95kfdXsZyvWPvdk+rsA+vZOTdY3X1D/OL6UHsu/9bq/T27b1r2xoX1be0fF2v8tnJvcduOV30vWTxgzLlm/Uhcm662AM/yAoAg/EBThB4Ii/EBQhB8IivADQZl7kRdGvt8JNskvskubtr+R1r7d2LDR37w42ojnkMmLt6Y3HhxoaN9bfzwvWd/88dYdeT1n/Zcr1k7+2Ycaeuxd8yxZ/+xllb/a+z+mNPb7UM2V08sZ6tvg67THd6efmAxHfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IKswU3W2W/js34IPJunvlodMtd3fW1dOwaz+anmp6+cl3V3mE8Q3tv0g9Fz9QuZi+krlUewb/lKwv+MG/JOsz9es82ykER34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCCrM9fyD62Ym60+fnZ6iu5UNJiarfs8PFLrvNqUvHR9oYCLtRh/7YOLcjYseuym57ew16eet7blivw+gXlzPD6Aqwg8ERfiBoAg/EBThB4Ii/EBQhB8Iqur1/GY2U9KDkv5S0qCkZe7+fTObJOlRSbMk9Uq6xt3fLa7VxnRclx76PPPWryTrW6+4v+59/3t/ejrob055KVn/fO9lyfprT55dsXbqd4q9rrztrDOSde/bUbl28FBy2zFzZiXrA69vTtZTztRv6972WFHLkf+QpJvc/RxJfyvpejM7V9LNkta5+xxJ67L7AI4SVcPv7jvcfWN2e6+kHknTJS2StDJbbaWkxUU1CSB/R/Se38xmSZonaYOkqe6+Qxr6AyFpSt7NAShOzeE3s4mSHpf0dXffcwTbdZlZt5l1H9T+enoEUICawm9m7RoK/kPu/kS2eKeZTcvq0yT1j7atuy9z905372zX2Dx6BpCDquE3M5O0XFKPu393RGmNpKXZ7aWSjt7L4oCAql7Sa2Yfk/S8pFc0NNQnSbdo6H3/TyR9WNKbkq52992pxyrzkt5qrL0jWR8zO31JcEpquEuSbMa0ZH1gy7YqO2jeZdlobUdySW/VcX53/5VU8cLq1kwygKo4ww8IivADQRF+ICjCDwRF+IGgCD8QVJgpuqvxg+mvah7Y/Lvidl7kYwMVcOQHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgqobfzGaa2XNm1mNmr5nZP2XLbzOzt83spezflcW3CyAvtUzacUjSTe6+0cyOl/SimT2b1e5y9/8qrj0ARakafnffIWlHdnuvmfVIml50YwCKdUTv+c1slqR5kjZki24ws5fNbIWZnVRhmy4z6zaz7oPa31CzAPJTc/jNbKKkxyV93d33SLpX0hmS5mrolcGdo23n7svcvdPdO9s1NoeWAeShpvCbWbuGgv+Quz8hSe6+090H3H1Q0v2S5hfXJoC81fJpv0laLqnH3b87Yvm0Eat9RtKr+bcHoCi1fNq/QNIXJL1iZi9ly26RtMTM5kpySb2SvlpIhwAKUcun/b+SZKOU1ubfDoBm4Qw/ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUObuzduZ2S5Jfxix6BRJf2xaA0emVXtr1b4keqtXnr2d5u6Ta1mxqeH/wM7Nut29s7QGElq1t1btS6K3epXVGy/7gaAIPxBU2eFfVvL+U1q1t1btS6K3epXSW6nv+QGUp+wjP4CSlBJ+M1toZpvMbKuZ3VxGD5WYWa+ZvZLNPNxdci8rzKzfzF4dsWySmT1rZluyn6NOk1ZSby0xc3NiZulSn7tWm/G66S/7zaxN0mZJl0vqk/SCpCXu/npTG6nAzHoldbp76WPCZnaxpH2SHnT387Nld0ja7e63Z384T3L3f2uR3m6TtK/smZuzCWWmjZxZWtJiSV9Sic9doq9rVMLzVsaRf76kre6+zd0PSHpE0qIS+mh57r5e0u7DFi+StDK7vVJDvzxNV6G3luDuO9x9Y3Z7r6ThmaVLfe4SfZWijPBPl/TWiPt9aq0pv13SM2b2opl1ld3MKKZm06YPT58+peR+Dld15uZmOmxm6ZZ57uqZ8TpvZYR/tNl/WmnIYYG7Xyjpk5Kuz17eojY1zdzcLKPMLN0S6p3xOm9lhL9P0swR92dI2l5CH6Ny9+3Zz35Jq9V6sw/vHJ4kNfvZX3I/f9ZKMzePNrO0WuC5a6UZr8sI/wuS5pjZbDPrkHStpDUl9PEBZjYh+yBGZjZB0hVqvdmH10hamt1eKumpEnt5n1aZubnSzNIq+blrtRmvSznJJxvK+J6kNkkr3P3bTW9iFGZ2uoaO9tLQJKYPl9mbma2SdImGrvraKelWSU9K+omkD0t6U9LV7t70D94q9HaJhl66/nnm5uH32E3u7WOSnpf0iqTBbPEtGnp/Xdpzl+hriUp43jjDDwiKM/yAoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwT1/4RhC4UonyXFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADddJREFUeJzt3X2MXPV1xvHn8bJ+iZ02OJS15UAM2GlNqWKqraF1SkGIBKKkdlRBsNTIbZM4rSAiEk2LrFQgtZVoUqAIEdJNcTERAdISgttaaSwLBFEqwCArECjgggOujU1iXgzFxi+nf+x1tDY7v1nm7c5yvh/Jmpl77p17NPKzd2Z+987PESEA+UypuwEA9SD8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSOqaXO5vqaTFdM3u5SyCVvXpDb8U+T2TdtsJv+3xJ10sakPRPEXF1af3pmqkzfG47uwRQ8GBsnPC6Lb/ttz0g6UZJF0g6VdIK26e2+nwAequdz/xLJG2JiGcj4i1Jd0ha1pm2AHRbO+GfJ+mFMY+3VcuOYHuV7U22N+3XvjZ2B6CT2gn/eF8qvO364IgYiYjhiBge1LQ2dgegk9oJ/zZJJ4x5/AFJ29trB0CvtBP+hyUttH2S7amSLpa0rjNtAei2lof6IuKA7Usl/adGh/rWRMRPOtYZgK5qa5w/ItZLWt+hXgD0EKf3AkkRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kFRbs/Ta3ippj6SDkg5ExHAnmkL/GFhwUrF+cMtzLT/3nk+fWaw/cO3Xi/XLtv92sf7Mb+17xz1l0lb4K+dExM868DwAeoi3/UBS7YY/JP3A9iO2V3WiIQC90e7b/qURsd328ZI22P7viLh/7ArVH4VVkjRd72lzdwA6pa0jf0Rsr253Sbpb0pJx1hmJiOGIGB7UtHZ2B6CDWg6/7Zm233v4vqSPSnq8U40B6K523vYPSbrb9uHn+XZEfL8jXQHoupbDHxHPSvpwB3tBFxwzZ6hYP+Xfdxfrf3bcbcX6imv+vFgfuuFHDWsvLdtb3PaQolj/6twHivXzl1/asDbjew8Vt82AoT4gKcIPJEX4gaQIP5AU4QeSIvxAUp24qg81G3jfLzesLfyPnxe3vWZOecjrUJOzMoeWP1+sv/JK48tu7/qd64rbSoNN6mgHR34gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIpx/neBp7+yqGHtnjk3Ntnabe37Wx+6s1g/4/cua1j79cGpxW2bXdL70L7pxTqX7ZZx5AeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpBjnnwQG3j+7WP+bTzYea5/S5jh+s+3fP2VGsb7lgpGu7fve1xuf34DmOPIDSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFJNx/ltr5H0CUm7IuK0atlsSXdKmi9pq6SLIuLl7rWZ256zFhbrfzBrQ8PaoSbP3Wws/dqXy/u+5akzi/XNZ97a8r43vFk+h+DeK5cW6zPE9fwlEzny3yLp/KOWXSFpY0QslLSxegxgEmka/oi4X9LuoxYvk7S2ur9W0vIO9wWgy1r9zD8UETskqbo9vnMtAeiFrp/bb3uVpFWSNF3v6fbuAExQq0f+nbbnSlJ1u6vRihExEhHDETE82GTSRwC902r410laWd1fKemezrQDoFeaht/27ZL+S9Kv2t5m+7OSrpZ0nu1nJJ1XPQYwiTT9zB8RKxqUzu1wL2hg28fKv1/fjm+8+sFi/Z/v/Fixvuri9Z1s5wiXPfLpYn0+v8vfFs7wA5Ii/EBShB9IivADSRF+ICnCDyTFT3cn9y9fPvqCzSMd+8UXi/VL3vc/Le/7r3YtLtZPXvl0sd7scmWUceQHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQY558EFty2v1if8snWp+H+02v/tVi/cNbPmzxD6/ted8dHivV5e3/U8nOjOY78QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4/yTwNStLxXrG99sPBPSOTP2FrdtNo5/SO39bPii+z7XsHbK3zGOXyeO/EBShB9IivADSRF+ICnCDyRF+IGkCD+QVNNxfttrJH1C0q6IOK1adpWkz0s6PAC9OiK6N1dzcgde2Fasr3/1ww1r58x4sNPtHGHnwTeL9ZNv5Nf1+9VEjvy3SBpvZofrImJx9Y/gA5NM0/BHxP2SdvegFwA91M5n/ktt/9j2GtvHdqwjAD3RavhvknSKpMWSdki6ptGKtlfZ3mR7037ta3F3ADqtpfBHxM6IOBgRhyR9U9KSwrojETEcEcODanwBCoDeain8tueOefgpSY93ph0AvTKRob7bJZ0t6Tjb2yRdKels24slhaStkr7QxR4BdEHT8EfEinEW39yFXtCif3viNxrWvjanu+P8QwMzivXtZ81sWJvH5fy14gw/ICnCDyRF+IGkCD+QFOEHkiL8QFL8dPckMLBoYbF+9+/e1LA2RVPb2veUNqbgliQtebW97dE1HPmBpAg/kBThB5Ii/EBShB9IivADSRF+ICnG+SeDr79RLC8aHGxYazbF9pdfPKNY/+Jx9xXrJx5TvqQ32pvhG13EkR9IivADSRF+ICnCDyRF+IGkCD+QFOEHkmKcfxL4ixO/37Xn3vyV04v1F298qFg/8RgG8icrjvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kFTTcX7bJ0i6VdIcSYckjUTE9bZnS7pT0nxJWyVdFBEvd6/Vd6+BBScV60MDzeayntawsui+zxW3PPj75d/lXzKNcfx3q4kc+Q9IujwiFkk6U9Iltk+VdIWkjRGxUNLG6jGASaJp+CNiR0Q8Wt3fI+lJSfMkLZO0tlptraTl3WoSQOe9o8/8tudLOl3Sg5KGImKHNPoHQtLxnW4OQPdMOPy2Z0m6S9KXIuK1d7DdKtubbG/ar32t9AigCyYUftuDGg3+bRHx3WrxTttzq/pcSbvG2zYiRiJiOCKGBwtfTAHorabht21JN0t6MiKuHVNaJ2lldX+lpHs63x6AbpnIJb1LJX1G0mO2N1fLVku6WtJ3bH9W0vOSLuxOi2imNI32U2ffXNx2wOW//wejvSm6/2/XzLa2R/c0DX9E/FBq+L/r3M62A6BXOMMPSIrwA0kRfiApwg8kRfiBpAg/kBQ/3d0HDm55rljfeXBWsb5gcH/rO49DxXKzKb7XvXFssb7ohlca1g4Wt0S3ceQHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQY558E/uSBPy7WnzpvpGv7fu7A3mL9r2/4w2J96IlmPzuOunDkB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkGOefBH7t8vL1/h/62hca1v7xrLUNa5J01+7hYv2nlywo1oceZhx/suLIDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJOaL8u+y2T5B0q6Q5kg5JGomI621fJenzkl6qVl0dEetLz/VLnh1nmFm9gW55MDbqtdjtiaw7kZN8Dki6PCIetf1eSY/Y3lDVrouIv2+1UQD1aRr+iNghaUd1f4/tJyXN63ZjALrrHX3mtz1f0umSHqwWXWr7x7bX2B533ibbq2xvsr1pv/a11SyAzplw+G3PknSXpC9FxGuSbpJ0iqTFGn1ncM1420XESEQMR8TwoKZ1oGUAnTCh8Nse1Gjwb4uI70pSROyMiIMRcUjSNyUt6V6bADqtafhtW9LNkp6MiGvHLJ87ZrVPSXq88+0B6JaJfNu/VNJnJD1me3O1bLWkFbYXSwpJWyU1vq4UQN+ZyLf9P5Q03rhhcUwfQH/jDD8gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBSTX+6u6M7s1+S9NMxi46T9LOeNfDO9Gtv/dqXRG+t6mRvH4yIX5nIij0N/9t2bm+KiPIE8TXp1976tS+J3lpVV2+87QeSIvxAUnWHf6Tm/Zf0a2/92pdEb62qpbdaP/MDqE/dR34ANakl/LbPt/2U7S22r6ijh0Zsb7X9mO3NtjfV3Msa27tsPz5m2WzbG2w/U92OO01aTb1dZft/q9dus+2P19TbCbbvtf2k7Z/YvqxaXutrV+irltet52/7bQ9IelrSeZK2SXpY0oqIeKKnjTRge6uk4YiofUzY9lmSXpd0a0ScVi37qqTdEXF19Yfz2Ij4yz7p7SpJr9c9c3M1oczcsTNLS1ou6Y9U42tX6Osi1fC61XHkXyJpS0Q8GxFvSbpD0rIa+uh7EXG/pN1HLV4maW11f61G//P0XIPe+kJE7IiIR6v7eyQdnlm61teu0Fct6gj/PEkvjHm8Tf015XdI+oHtR2yvqruZcQxV06Yfnj79+Jr7OVrTmZt76aiZpfvmtWtlxutOqyP8483+009DDksj4jclXSDpkurtLSZmQjM398o4M0v3hVZnvO60OsK/TdIJYx5/QNL2GvoYV0Rsr253Sbpb/Tf78M7Dk6RWt7tq7ucX+mnm5vFmllYfvHb9NON1HeF/WNJC2yfZnirpYknraujjbWzPrL6Ike2Zkj6q/pt9eJ2kldX9lZLuqbGXI/TLzM2NZpZWza9dv814XctJPtVQxj9IGpC0JiL+tudNjMP2yRo92kujk5h+u87ebN8u6WyNXvW1U9KVkr4n6TuSTpT0vKQLI6LnX7w16O1sjb51/cXMzYc/Y/e4t49IekDSY5IOVYtXa/TzdW2vXaGvFarhdeMMPyApzvADkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5DU/wO4Cskeg90RnwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADVZJREFUeJzt3X+s1fV9x/HXS7zABDU4q2VCBZV1VZPSeoNmLo2N2mnXBbtVU9MsLDGlWdC1mUtqTNbyx5aYrrYzW1dzrayQCdqsVdlKNg3ZQru1zKt1YEWnZRQYjIuhUbROfr33x/2y3OI9n3M553vO9+D7+UjIOef7/v5454TX/X7P+ZxzPo4IAcjntKYbANAMwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+IKnT+3mw6Z4RMzWrn4cEUvlfvaFD8Zansm5X4bd9g6T7JE2T9I2IuKe0/kzN0pW+tptDAijYHBunvG7Hl/22p0n6mqQbJV0q6Vbbl3a6PwD91c1r/iWSXo6I7RFxSNLDkpbW0xaAXusm/BdI2jXh8e5q2S+wvdz2qO3Rw3qri8MBqFM34Z/sTYW3fT84IkYiYjgihoc0o4vDAahTN+HfLWn+hMfzJO3prh0A/dJN+J+StMj2QtvTJX1S0vp62gLQax0P9UXEEdu3S/onjQ/1rYqIH9fWGYCe6mqcPyI2SNpQUy8A+oiP9wJJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5BUV7P02t4h6aCko5KORMRwHU0B6L2uwl/5cES8UsN+APQRl/1AUt2GPyQ9Yftp28vraAhAf3R72X91ROyxfZ6kJ22/EBGbJq5Q/VFYLkkzdUaXhwNQl67O/BGxp7odk/SopCWTrDMSEcMRMTykGd0cDkCNOg6/7Vm2zzx+X9JHJD1XV2MAequby/7zJT1q+/h+1kbEP9bSFYCe6zj8EbFd0vtr7AUNOO397yvWl6zZUqx/4dytxfqv/e2KlrWLPv+D4rboLYb6gKQIP5AU4QeSIvxAUoQfSIrwA0nV8a0+NOy0mTNb1g5dfVlx28/ev65Y/80zXi3Wr3v+E8X6wsd+3rK2c+Wvl7d96H+K9aMvbS/WUcaZH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSYpz/FFAax5ekXWsvbln70ZUjXR37sjV/WKxf+N03i/XfefDJlrXbzt5Z3PbDV91crM+6oVhGG5z5gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApxvlPAS/eX/5O/otdjOUP//kdxfq85w8V62vW/lWxfu60XzrpntAfnPmBpAg/kBThB5Ii/EBShB9IivADSRF+IKm24/y2V0n6mKSxiLi8WnaOpEckLZC0Q9ItEfGz3rX5zja2ovz79T+67t42e5jesvKrf/8HxS298FixvumP/7JYP8O9G8ffu//sYv2Snh05h6mc+b8p6cSfTbhL0saIWCRpY/UYwCmkbfgjYpOkAycsXippdXV/taSbau4LQI91+pr//IjYK0nV7Xn1tQSgH3r+2X7byyUtl6SZOqPXhwMwRZ2e+ffZnitJ1e1YqxUjYiQihiNieEgzOjwcgLp1Gv71kpZV95dJeryedgD0S9vw214n6QeS3mt7t+3bJN0j6XrbL0m6vnoM4BTS9jV/RNzaonRtzb2kdfbSPcX6bHf+cunl376/420laezo0WJ99jR3vO83o/xbAe/9o93FerkztMMn/ICkCD+QFOEHkiL8QFKEH0iK8ANJ8dPdA2D/v/xKsX7ssuh431sOlQfEbn+h1UjuuDl3TivWv/AP64r1KwqjlB/83meK2y7c/x/FOrrDmR9IivADSRF+ICnCDyRF+IGkCD+QFOEHkmKcfwDM/9K/F+sf+q8Vxfrs3W+1rE3fsb+47Vm7flKsb/ubK4r10jh+Oxd+rfOvA6N7nPmBpAg/kBThB5Ii/EBShB9IivADSRF+ICnG+QdAHDlSrJ+17ocd77u85/auu/SFrrZ/4s1ZLWtDL+wqbstPc/cWZ34gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSKrtOL/tVZI+JmksIi6vlq2U9GlJx78sfndEbOhVk+idn3z5qmJ9w7y/LtaPtdn/HRuWtawtemVzm63RS1M5839T0g2TLP9qRCyu/hF84BTTNvwRsUnSgT70AqCPunnNf7vtLbZX2Z5TW0cA+qLT8H9d0sWSFkvaK+neVivaXm571PboYbX+rTkA/dVR+CNiX0QcjYhjkh6QtKSw7khEDEfE8JC6+LVHALXqKPy25054+HFJz9XTDoB+mcpQ3zpJ10g61/ZuSV+UdI3txZJC0g5J5bmWAQyctuGPiMkmcH+wB72gAbMuebVYn+byxeGROFysX/II7/MMKj7hByRF+IGkCD+QFOEHkiL8QFKEH0iKn+5Obu3iVcX60Sh/KvNT228s1v2vz550T+gPzvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBTj/O9wb3ziymL9wtM7n/5bknZ+Y1GxPkevdLV/9A5nfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IinH+d7hXP3WwWJ/hoWL94dffVaz/8t9tKdbbTeGN5nDmB5Ii/EBShB9IivADSRF+ICnCDyRF+IGk2o7z254vaY2kd2t82HYkIu6zfY6kRyQtkLRD0i0R8bPetYpO/Mll3+1q+z/d8tFi/T1vbO1q/2jOVM78RyTdGRHvk3SVpBW2L5V0l6SNEbFI0sbqMYBTRNvwR8TeiHimun9Q0jZJF0haKml1tdpqSTf1qkkA9Tup1/y2F0j6gKTNks6PiL3S+B8ISefV3RyA3ply+G3PlvRtSZ+LiNdOYrvltkdtjx7WW530CKAHphR+20MaD/5DEfGdavE+23Or+lxJY5NtGxEjETEcEcNDKk/6CKB/2obftiU9KGlbRHxlQmm9pGXV/WWSHq+/PQC9MpWv9F4t6fckbbV9fL7luyXdI+lbtm+TtFPSzb1pEe0cvu6KlrXfnfVMm61drM7eMLuDjnAqaBv+iPi+Wv8PubbedgD0C5/wA5Ii/EBShB9IivADSRF+ICnCDyTFT3e/A/z0t1r//PYxRVf7Hvp5d9tjcHHmB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkGOdH0ZmP/LDpFtAjnPmBpAg/kBThB5Ii/EBShB9IivADSRF+ICnG+VF0+kULivUj23f0pQ/UjzM/kBThB5Ii/EBShB9IivADSRF+ICnCDyTVdpzf9nxJayS9W9IxSSMRcZ/tlZI+LWl/terdEbGhV42itYsee6tl7eml5W1ve+COYn3e9n/rpCWcAqbyIZ8jku6MiGdsnynpadtPVrWvRsSXe9cegF5pG/6I2Ctpb3X/oO1tki7odWMAeuukXvPbXiDpA5I2V4tut73F9irbc1pss9z2qO3Rw2p9eQqgv6YcftuzJX1b0uci4jVJX5d0saTFGr8yuHey7SJiJCKGI2J4SDNqaBlAHaYUfttDGg/+QxHxHUmKiH0RcTQijkl6QNKS3rUJoG5tw2/bkh6UtC0ivjJh+dwJq31c0nP1twegVxxRnoLZ9m9I+p6krRof6pOkuyXdqvFL/pC0Q9JnqjcHWzrL58SVvrbLlgG0sjk26rU44KmsO5V3+78vabKdMaYPnML4hB+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiCptt/nr/Vg9n5JP52w6FxJr/StgZMzqL0Nal8SvXWqzt4ujIh3TWXFvob/bQe3RyNiuLEGCga1t0HtS6K3TjXVG5f9QFKEH0iq6fCPNHz8kkHtbVD7kuitU4301uhrfgDNafrMD6AhjYTf9g22X7T9su27muihFds7bG+1/azt0YZ7WWV7zPZzE5adY/tJ2y9Vt5NOk9ZQbytt/3f13D1r+6MN9Tbf9j/b3mb7x7Y/Wy1v9Lkr9NXI89b3y37b0yT9p6TrJe2W9JSkWyPi+b420oLtHZKGI6LxMWHbH5L0uqQ1EXF5texLkg5ExD3VH845EfH5AeltpaTXm565uZpQZu7EmaUl3STp99Xgc1fo6xY18Lw1ceZfIunliNgeEYckPSypzSzyOUXEJkkHTli8VNLq6v5qjf/n6bsWvQ2EiNgbEc9U9w9KOj6zdKPPXaGvRjQR/gsk7ZrweLcGa8rvkPSE7adtL2+6mUmcf3xmpOr2vIb7OVHbmZv76YSZpQfmuetkxuu6NRH+yWb/GaQhh6sj4oOSbpS0orq8xdRMaebmfplkZumB0OmM13VrIvy7Jc2f8HiepD0N9DGpiNhT3Y5JelSDN/vwvuOTpFa3Yw338/8GaebmyWaW1gA8d4M043UT4X9K0iLbC21Pl/RJSesb6ONtbM+q3oiR7VmSPqLBm314vaRl1f1lkh5vsJdfMCgzN7eaWVoNP3eDNuN1Ix/yqYYy/kLSNEmrIuLP+t7EJGxfpPGzvTQ+ienaJnuzvU7SNRr/1tc+SV+U9Jikb0l6j6Sdkm6OiL6/8dait2t0kjM396i3VjNLb1aDz12dM17X0g+f8ANy4hN+QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeS+j9JhbUr9puaeAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADlpJREFUeJzt3X+MXXWZx/HP02HaQmlJp9JSSkuhNgKyUpfZurslUhdRfiXFqCgx2m3QIRvYpVk3u6T+ATHZbLNZZHFX2YwyUlR+mGilGgKSSgS0VgastDq11mYWptNtwRpaEPqLZ/+Y092xzPne23vPuedOn/crIXPvec6Phwufe+7M957zNXcXgHgmVN0AgGoQfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQZ3UyoNNtEk+WVNaeUgglDf0mg76Aatn3abCb2ZXSLpLUoekr7r76tT6kzVF77HLmjkkgISNvr7udRv+2G9mHZK+JOlKSRdIut7MLmh0fwBaq5nf+RdL2u7uO9z9oKQHJS0rpi0AZWsm/HMkvTjq+VC27I+YWY+Z9ZtZ/yEdaOJwAIrUTPjH+qPCW64Pdvded+929+5OTWricACK1Ez4hyTNHfX8LEnDzbUDoFWaCf8zkhaa2TlmNlHSxyWtK6YtAGVreKjP3Q+b2c2SHtPIUF+fu/+ysM4AlKqpcX53f0TSIwX1AqCF+HovEBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQTU1S6+ZDUraL+mIpMPu3l1EUwDK11T4M+9z95cL2A+AFuJjPxBUs+F3ST8ws2fNrKeIhgC0RrMf+5e4+7CZzZT0uJltdfcnR6+QvSn0SNJkndLk4QAUpakzv7sPZz/3SForafEY6/S6e7e7d3dqUjOHA1CghsNvZlPMbOrRx5I+IGlLUY0BKFczH/tnSVprZkf3c7+7P1pIVwBK13D43X2HpIsK7AU5OqZNS9aPrM2vP3b+95Pbnrv2xmR94U0bk/UqdczoStYHVi/IrU1+sTO57bzP/6ShnsYThvqAoAg/EBThB4Ii/EBQhB8IivADQRVxVR9KtvVfzk/WB877z9zaIU+/v3dtGr/v/9PWpevb5v9Xbu2W4SXJbX/7+UY6Gl/G7395AE0h/EBQhB8IivADQRF+ICjCDwRF+IGgGOdvAyfNOTNZ9843G9737iOvJ+tTXzzc8L7L1vGOtyfrf3/mAzX2kH9ue2JwYXLLedpcY9/jH2d+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiKcf428Nq75iTrW6/+csP7/siqf0jWT3v0pw3vu2y7Lz09Wb9oYnr7Fw7nf8fhrC/yvz5nfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IquZgp5n1SbpG0h53vzBb1iXpIUnzJQ1Kus7df19em+Nbx6yZyfq+v9mXrE+o8R6dGs+eMnwouW2VfMmiZL3rY0PJeq3X5YNP/21ubcFTP09uG0E9Z/57JV1xzLJbJa1394WS1mfPAYwjNcPv7k9K2nvM4mWS1mSP10i6tuC+AJSs0d/5Z7n7LknKfqY/1wJoO6V/wdnMeiT1SNJknVL24QDUqdEz/24zmy1J2c89eSu6e6+7d7t7d6cmNXg4AEVrNPzrJC3PHi+X9HAx7QBolZrhN7MHJG2Q9A4zGzKzGyStlnS5mf1G0uXZcwDjSM3f+d39+pzSZQX3csJ646J5yfqGi+9O1mvdtf+2ndfk1k764bPJbTvefk6ybq8fSNZr3YsgZebndiTrXz/n0WS91usy49HJx9lRLHzDDwiK8ANBEX4gKMIPBEX4gaAIPxAU9y9ugc/d/bVS9/+pmT/OrX2/P33Z7CXTfpis7z18arK+4rT097tSl92+WXOwLm3xM59K1s/68a7cWvtOTN46nPmBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjG+Qsw/I9/may/d3L6strmRrulS0/+Q27tfSenp+CuPdb+cgMdtcaEx6cn64d3DLSok/GJMz8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBMU4f51e7vmL3Npzt/xHctsJshp7b+49+InX829R/Xf3fzq9sad7u/qa9PcELp22Nb39Ka8mqul/76u2pud/ndXbn6x7sgrO/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QVM1xfjPrk3SNpD3ufmG27HZJn5H0UrbaKnd/pKwm28EfzsgfD699TXz6PXb54PuT9W33npesn/7gltza2fs3JLetZctt6fqmv8qbwX3ElV/vza3Vet32H5iUrE+fnK77oYPJenT1nPnvlXTFGMvvdPdF2T8ndPCBE1HN8Lv7k5L2tqAXAC3UzO/8N5vZ82bWZ2bp+ykBaDuNhv9uSQskLZK0S9IdeSuaWY+Z9ZtZ/yEdaPBwAIrWUPjdfbe7H3H3NyV9RdLixLq97t7t7t2dSv+BBkDrNBR+M5s96umHJOX/uRlAW6pnqO8BSUslvc3MhiTdJmmpmS3SyFWTg5JuLLFHACWoGX53H2sg954Semlrpw7lXx1+yc8/kdx20ek7k/VXrjs5WZ+xMz1W3+x9/1Ps4ncm63f2fanGHjobPvbrj81M1k/bv73hfYNv+AFhEX4gKMIPBEX4gaAIPxAU4QeC4tbdderqSwy39aW33TmjK1k/8rvhBjoa/64a+HCyPutnr7Wok5g48wNBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIzzt8CR343f+5/++oYpyfr5nelLdlPTk7/y0JzktjM2NHfbcaRx5geCIvxAUIQfCIrwA0ERfiAowg8ERfiBoBjnD67Wrbmv/rNfJOu1ptm+aMOK3Nr8H+1JbnskWUWzOPMDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFA1x/nNbK6k+ySdoZHZoHvd/S4z65L0kKT5kgYlXefuvy+vVZThjZmnJOt3nPl0U/tfcV7+NfkP/8n7k9tO2fbbpo6NtHrO/Iclfdbdz5f055JuMrMLJN0qab27L5S0PnsOYJyoGX533+Xuz2WP90sakDRH0jJJa7LV1ki6tqwmARTvuH7nN7P5kt4taaOkWe6+Sxp5g5A0s+jmAJSn7vCb2amSvi1ppbvvO47tesys38z6D+lAIz0CKEFd4TezTo0E/5vu/p1s8W4zm53VZ0sa8yoNd+9192537+7UpCJ6BlCAmuE3M5N0j6QBd//CqNI6Scuzx8slPVx8ewDKUs8lvUskfVLSZjPblC1bJWm1pG+Z2Q2SXpD00XJaRJn+Z8Ubpe5/5fRtubVvzPtgctv0TcPRrJrhd/enpdybr19WbDsAWoVv+AFBEX4gKMIPBEX4gaAIPxAU4QeC4tbdJzjrnJisnz0jfRX2hCbPD9sP5X+l+7U56dt+o1yc+YGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMb5T3B7P3Fxsv7UeV9M1psdib9x5crc2oLv/rTJvaMZnPmBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjG+U9wE/eXe838V185N1mf+vyYEzlJGpn+GdXhzA8ERfiBoAg/EBThB4Ii/EBQhB8IivADQdUc5zezuZLuk3SGRi7v7nX3u8zsdkmfkfRStuoqd3+krEbRmINT0+/vX3tlfrK+4rTBZP17y5cm675jc7KO6tTzJZ/Dkj7r7s+Z2VRJz5rZ41ntTnf/t/LaA1CWmuF3912SdmWP95vZgKQ5ZTcGoFzH9Tu/mc2X9G5JG7NFN5vZ82bWZ2bTc7bpMbN+M+s/pPypmwC0Vt3hN7NTJX1b0kp33yfpbkkLJC3SyCeDO8bazt173b3b3bs7NamAlgEUoa7wm1mnRoL/TXf/jiS5+253P+Lub0r6iqTF5bUJoGg1w29mJukeSQPu/oVRy2ePWu1DkrYU3x6Aspi7p1cwu0TSU5I26//v5LxK0vUa+cjvkgYl3Zj9cTDXNOvy99hlTbYMIM9GX699vtfqWbeev/Y/LWmsnTGmD4xjfMMPCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QVM3r+Qs9mNlLkv571KK3SXq5ZQ0cn3btrV37kuitUUX2dra7n17Pii0N/1sObtbv7t2VNZDQrr21a18SvTWqqt742A8ERfiBoKoOf2/Fx09p197atS+J3hpVSW+V/s4PoDpVn/kBVKSS8JvZFWb2azPbbma3VtFDHjMbNLPNZrbJzPor7qXPzPaY2ZZRy7rM7HEz+032c8xp0irq7XYz25m9dpvM7KqKeptrZk+Y2YCZ/dLMbsmWV/raJfqq5HVr+cd+M+uQtE3S5ZKGJD0j6Xp3/1VLG8lhZoOSut298jFhM3uvpFcl3efuF2bL/lXSXndfnb1xTnf3f2qT3m6X9GrVMzdnE8rMHj2ztKRrJf21KnztEn1dpwpetyrO/IslbXf3He5+UNKDkpZV0Efbc/cnJe09ZvEySWuyx2s08j9Py+X01hbcfZe7P5c93i/p6MzSlb52ib4qUUX450h6cdTzIbXXlN8u6Qdm9qyZ9VTdzBhmHZ0ZKfs5s+J+jlVz5uZWOmZm6bZ57RqZ8bpoVYR/rNl/2mnIYYm7/6mkKyXdlH28RX3qmrm5VcaYWbotNDrjddGqCP+QpLmjnp8labiCPsbk7sPZzz2S1qr9Zh/efXSS1Oznnor7+T/tNHPzWDNLqw1eu3aa8bqK8D8jaaGZnWNmEyV9XNK6Cvp4CzObkv0hRmY2RdIH1H6zD6+TtDx7vFzSwxX28kfaZebmvJmlVfFr124zXlfyJZ9sKOPfJXVI6nP3f255E2Mws3M1craXRiYxvb/K3szsAUlLNXLV125Jt0n6rqRvSZon6QVJH3X3lv/hLae3pTrOmZtL6i1vZumNqvC1K3LG60L64Rt+QEx8ww8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFD/C2b28smZbbxmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in np.random.randint(0,m,25):\n",
    "    print(subm.iloc[i]['Label'])\n",
    "    plt.imshow(X_subm[i,:,:,0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(mx_train, my_train), (mx_test, my_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx_train = mx_train.reshape(60000,28,28,1)\n",
    "mx_test = mx_test.reshape(10000,28,28,1)\n",
    "mx = np.concatenate((mx_train, mx_test), axis=0)\n",
    "my = np.concatenate((my_train, my_test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6157    0   19    3  632    0   18    3    1   70]\n",
      " [   7 1333   47   10 6259    7  179   26    5    4]\n",
      " [   0    1 6949    4   36    0    0    0    0    0]\n",
      " [   0    0   20 7096    2   17    0    3    2    1]\n",
      " [   0    0    0    0 6809    0    2    1    0   12]\n",
      " [   0    0    4   20    3 6281    4    0    0    1]\n",
      " [   3    0    1    8   61   52 6751    0    0    0]\n",
      " [   0    3  256    4   60    0    0 6967    3    0]\n",
      " [   5    0   76   26   63   29   21    0 6585   20]\n",
      " [   0    0   11   40   79   23    0   19    7 6779]]\n"
     ]
    }
   ],
   "source": [
    "## with Keras data augmentation\n",
    "Y_test_pred = model.predict_classes(mx)\n",
    "Y_test_true = my\n",
    "\n",
    "print(confusion_matrix(Y_test_true, Y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5291    0   12    0    0    0  186    0 1412    2]\n",
      " [   0    0 1359    1    5    0   17    0 6483   12]\n",
      " [   0    0 6902    0    0    0    1    0   83    4]\n",
      " [   0    0   39 6807    0    3    1    0  285    6]\n",
      " [   1    0   42    0 5926    0  228    0  296  331]\n",
      " [   0    0    1   11    0 5458   85    0  711   47]\n",
      " [   0    0    2    0    0    0 6803    0   71    0]\n",
      " [   2    0  738   99   44    3   10 2153  230 4014]\n",
      " [   0    0    2    0    0    0    3    0 6817    3]\n",
      " [   3    0    3    0    0    0    6    0   79 6867]]\n"
     ]
    }
   ],
   "source": [
    "## without Keras data augmentation, complicated network\n",
    "Y_test_pred = model.predict_classes(mx)\n",
    "Y_test_true = my\n",
    "\n",
    "print(confusion_matrix(Y_test_true, Y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6893    1    1    0    0    0    1    2    2    3]\n",
      " [   0 7851   10    0    0    0    0   16    0    0]\n",
      " [   2    1 6941    5    2    0    3   23   10    3]\n",
      " [   0    0    4 7118    0    2    0   11    3    3]\n",
      " [   1    9    2    0 6776    0    3    5    1   27]\n",
      " [   2    2    1    8    0 6280   12    1    5    2]\n",
      " [   9    7    1    2    6    4 6841    0    6    0]\n",
      " [   0    5    1    0    8    2    0 7273    0    4]\n",
      " [   3   11    6    7    6    6    2    9 6758   17]\n",
      " [   5    3    0    7    8    5    0   24    1 6905]]\n"
     ]
    }
   ],
   "source": [
    "## without Keras data augmentation, simpler network\n",
    "Y_test_pred = model.predict_classes(mx)\n",
    "Y_test_true = my\n",
    "\n",
    "print(confusion_matrix(Y_test_true, Y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only one additional fully connected layer, add average pooling \n",
    "# instead of stride and dropout before flattening for regularization\n",
    "\n",
    "def cnn3_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(10, (3,3), input_shape=(28, 28, 1), activation='relu'))\n",
    "    model.add(Conv2D(20, (3,3), activation='relu')) #change from 5 to 3\n",
    "    model.add(AveragePooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(40, (3,3), activation='relu')) #change from 5 to 3\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu')) #added additional fully connected layer\n",
    "    model.add(Dropout(0.2)) #added\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.2)) #added\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.3014 - acc: 0.9093 - val_loss: 0.1024 - val_acc: 0.9693\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 2s 49us/step - loss: 0.0790 - acc: 0.9757 - val_loss: 0.0636 - val_acc: 0.9800\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 2s 49us/step - loss: 0.0521 - acc: 0.9840 - val_loss: 0.0564 - val_acc: 0.9826\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 2s 50us/step - loss: 0.0402 - acc: 0.9870 - val_loss: 0.0449 - val_acc: 0.9862\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 2s 49us/step - loss: 0.0325 - acc: 0.9898 - val_loss: 0.0473 - val_acc: 0.9855\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 2s 49us/step - loss: 0.0277 - acc: 0.9908 - val_loss: 0.0429 - val_acc: 0.9883\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 2s 48us/step - loss: 0.0235 - acc: 0.9925 - val_loss: 0.0449 - val_acc: 0.9864\n",
      "Epoch 8/10\n",
      "37800/37800 [==============================] - 2s 48us/step - loss: 0.0186 - acc: 0.9942 - val_loss: 0.0418 - val_acc: 0.9895\n",
      "Epoch 9/10\n",
      "37800/37800 [==============================] - 2s 48us/step - loss: 0.0145 - acc: 0.9953 - val_loss: 0.0481 - val_acc: 0.9883\n",
      "Epoch 10/10\n",
      "37800/37800 [==============================] - 2s 48us/step - loss: 0.0157 - acc: 0.9952 - val_loss: 0.0515 - val_acc: 0.9855\n",
      "Epoch 00010: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3b6b7bea90>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = cnn3_model()\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, callbacks=[EarlyStopping(monitor='val_acc', min_delta=0.001, patience=2, verbose=1, mode='auto')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6890    1    0    0    1    0    6    1    3    1]\n",
      " [   1 7831   12    2    1    3    4   14    3    6]\n",
      " [  11    3 6948    5    4    0    3    3   11    2]\n",
      " [   4    1    7 7098    0    8    1    4   14    4]\n",
      " [   3    2    0    0 6779    2    7    2    2   27]\n",
      " [  12    2    1   17    1 6197   40    2   21   20]\n",
      " [  10    2    0    0    4    3 6856    0    1    0]\n",
      " [   7    7   61   15    9    2    0 7158    5   29]\n",
      " [   7    5    9    5    5    5   11    3 6765   10]\n",
      " [  10    2    0   15   21    9    1    6    7 6887]]\n"
     ]
    }
   ],
   "source": [
    "## with Keras without batch normalization\n",
    "Y_test_pred = model.predict_classes(mx)\n",
    "Y_test_true = my\n",
    "\n",
    "print(confusion_matrix(Y_test_true, Y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6883    4    2    1    1    0    9    1    2    0]\n",
      " [   0 7854   12    0    0    2    0    7    2    0]\n",
      " [   5    3 6974    0    1    0    2    1    4    0]\n",
      " [   0    2   17 7093    0   22    0    5    1    1]\n",
      " [   4   23    5    0 6740    3   15    2    2   30]\n",
      " [   4    1    2    8    0 6280   16    0    2    0]\n",
      " [   8   12    0    0    2    7 6847    0    0    0]\n",
      " [   4   17   36    4    7   10    0 7204    7    4]\n",
      " [   9   22   21    5    4   25   16    1 6721    1]\n",
      " [  17   11    1   24   15   41    0   28    4 6817]]\n"
     ]
    }
   ],
   "source": [
    "## with Keras without batch normalization\n",
    "Y_test_pred = model.predict_classes(mx)\n",
    "Y_test_true = my\n",
    "\n",
    "print(confusion_matrix(Y_test_true, Y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9915571428571428\n",
      "ConvNet Error: 0.84%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(mx, np_utils.to_categorical(my), verbose=0)\n",
    "print(\"Accuracy: {}\".format(scores[1]))\n",
    "print(\"ConvNet Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9916142857142857"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(my, Y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 28, 28, 1)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submdata = pd.read_csv(\"./input/test.csv\")\n",
    "m = len(submdata)\n",
    "X_subm = np.array(submdata)\n",
    "X_subm = X_subm.reshape(m, 28, 28, 1).astype('float32')\n",
    "X_subm /= 255\n",
    "X_subm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 6s 153us/step - loss: 0.3543 - acc: 0.8887 - val_loss: 0.1020 - val_acc: 0.9669\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0975 - acc: 0.9703 - val_loss: 0.0807 - val_acc: 0.9755\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0675 - acc: 0.9791 - val_loss: 0.0581 - val_acc: 0.9821\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.0508 - acc: 0.9846 - val_loss: 0.0509 - val_acc: 0.9850\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0376 - acc: 0.9884 - val_loss: 0.0607 - val_acc: 0.9814\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0322 - acc: 0.9900 - val_loss: 0.0486 - val_acc: 0.9852\n",
      "Epoch 00006: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 6s 154us/step - loss: 0.3620 - acc: 0.8870 - val_loss: 0.1111 - val_acc: 0.9652\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.0893 - acc: 0.9730 - val_loss: 0.0636 - val_acc: 0.9795\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0600 - acc: 0.9815 - val_loss: 0.0551 - val_acc: 0.9821\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0478 - acc: 0.9844 - val_loss: 0.0491 - val_acc: 0.9855\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0367 - acc: 0.9887 - val_loss: 0.0506 - val_acc: 0.9860\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0328 - acc: 0.9895 - val_loss: 0.0502 - val_acc: 0.9874\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0268 - acc: 0.9915 - val_loss: 0.0392 - val_acc: 0.9888\n",
      "Epoch 8/10\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0231 - acc: 0.9928 - val_loss: 0.0391 - val_acc: 0.9900\n",
      "Epoch 9/10\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0211 - acc: 0.9931 - val_loss: 0.0450 - val_acc: 0.9881\n",
      "Epoch 10/10\n",
      "37800/37800 [==============================] - 2s 60us/step - loss: 0.0174 - acc: 0.9941 - val_loss: 0.0399 - val_acc: 0.9898\n",
      "Epoch 00010: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 6s 150us/step - loss: 0.3489 - acc: 0.8937 - val_loss: 0.1043 - val_acc: 0.9683\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.0904 - acc: 0.9722 - val_loss: 0.0645 - val_acc: 0.9790\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.0616 - acc: 0.9810 - val_loss: 0.0559 - val_acc: 0.9826\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0457 - acc: 0.9861 - val_loss: 0.0507 - val_acc: 0.9867\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0365 - acc: 0.9884 - val_loss: 0.0521 - val_acc: 0.9864\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0325 - acc: 0.9892 - val_loss: 0.0517 - val_acc: 0.9864\n",
      "Epoch 00006: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 6s 157us/step - loss: 0.3587 - acc: 0.8925 - val_loss: 0.1003 - val_acc: 0.9676\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.0956 - acc: 0.9711 - val_loss: 0.0692 - val_acc: 0.9762\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.0644 - acc: 0.9813 - val_loss: 0.0532 - val_acc: 0.9829\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0504 - acc: 0.9844 - val_loss: 0.0513 - val_acc: 0.9848\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0402 - acc: 0.9868 - val_loss: 0.0467 - val_acc: 0.9852\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0325 - acc: 0.9893 - val_loss: 0.0409 - val_acc: 0.9881\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 2s 60us/step - loss: 0.0255 - acc: 0.9917 - val_loss: 0.0408 - val_acc: 0.9893\n",
      "Epoch 8/10\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0229 - acc: 0.9929 - val_loss: 0.0380 - val_acc: 0.9886\n",
      "Epoch 9/10\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0183 - acc: 0.9939 - val_loss: 0.0405 - val_acc: 0.9898\n",
      "Epoch 00009: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 6s 157us/step - loss: 0.3685 - acc: 0.8850 - val_loss: 0.1132 - val_acc: 0.9679\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0896 - acc: 0.9724 - val_loss: 0.0665 - val_acc: 0.9798\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0606 - acc: 0.9815 - val_loss: 0.0530 - val_acc: 0.9838\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0443 - acc: 0.9869 - val_loss: 0.0501 - val_acc: 0.9843\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0373 - acc: 0.9884 - val_loss: 0.0424 - val_acc: 0.9874\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0278 - acc: 0.9910 - val_loss: 0.0483 - val_acc: 0.9874\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0234 - acc: 0.9924 - val_loss: 0.0439 - val_acc: 0.9883\n",
      "Epoch 00007: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 7s 179us/step - loss: 0.3766 - acc: 0.8838 - val_loss: 0.1028 - val_acc: 0.9690\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0904 - acc: 0.9723 - val_loss: 0.0589 - val_acc: 0.9814\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0629 - acc: 0.9802 - val_loss: 0.0487 - val_acc: 0.9845\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0483 - acc: 0.9847 - val_loss: 0.0471 - val_acc: 0.9852\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.0388 - acc: 0.9878 - val_loss: 0.0435 - val_acc: 0.9860\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.0292 - acc: 0.9909 - val_loss: 0.0405 - val_acc: 0.9881\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0261 - acc: 0.9919 - val_loss: 0.0434 - val_acc: 0.9888\n",
      "Epoch 8/10\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0228 - acc: 0.9922 - val_loss: 0.0445 - val_acc: 0.9898\n",
      "Epoch 9/10\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0198 - acc: 0.9938 - val_loss: 0.0353 - val_acc: 0.9895\n",
      "Epoch 10/10\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0170 - acc: 0.9946 - val_loss: 0.0406 - val_acc: 0.9893\n",
      "Epoch 00010: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 6s 156us/step - loss: 0.3397 - acc: 0.8968 - val_loss: 0.0867 - val_acc: 0.9721\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.0835 - acc: 0.9747 - val_loss: 0.0615 - val_acc: 0.9814\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 2s 64us/step - loss: 0.0554 - acc: 0.9829 - val_loss: 0.0516 - val_acc: 0.9848\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0419 - acc: 0.9872 - val_loss: 0.0633 - val_acc: 0.9824\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0330 - acc: 0.9896 - val_loss: 0.0438 - val_acc: 0.9874\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0280 - acc: 0.9918 - val_loss: 0.0458 - val_acc: 0.9874\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0246 - acc: 0.9922 - val_loss: 0.0473 - val_acc: 0.9886\n",
      "Epoch 8/10\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0186 - acc: 0.9940 - val_loss: 0.0569 - val_acc: 0.9879\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0179 - acc: 0.9947 - val_loss: 0.0460 - val_acc: 0.9900\n",
      "Epoch 10/10\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0159 - acc: 0.9946 - val_loss: 0.0546 - val_acc: 0.9883\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 6s 165us/step - loss: 0.3463 - acc: 0.8919 - val_loss: 0.0906 - val_acc: 0.9698\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.0868 - acc: 0.9729 - val_loss: 0.0605 - val_acc: 0.9812\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.0602 - acc: 0.9818 - val_loss: 0.0555 - val_acc: 0.9831\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.0465 - acc: 0.9855 - val_loss: 0.0429 - val_acc: 0.9871\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.0356 - acc: 0.9884 - val_loss: 0.0570 - val_acc: 0.9845\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.0320 - acc: 0.9896 - val_loss: 0.0478 - val_acc: 0.9843\n",
      "Epoch 00006: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 6s 163us/step - loss: 0.3420 - acc: 0.8965 - val_loss: 0.0873 - val_acc: 0.9721\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0835 - acc: 0.9747 - val_loss: 0.0673 - val_acc: 0.9783\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.0555 - acc: 0.9832 - val_loss: 0.0480 - val_acc: 0.9857\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - ETA: 0s - loss: 0.0428 - acc: 0.987 - 2s 62us/step - loss: 0.0425 - acc: 0.9871 - val_loss: 0.0418 - val_acc: 0.9871\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0324 - acc: 0.9894 - val_loss: 0.0368 - val_acc: 0.9890\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0291 - acc: 0.9910 - val_loss: 0.0399 - val_acc: 0.9898\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0230 - acc: 0.9928 - val_loss: 0.0487 - val_acc: 0.9869\n",
      "Epoch 00007: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 6s 169us/step - loss: 0.3280 - acc: 0.8988 - val_loss: 0.1020 - val_acc: 0.9671\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 2s 64us/step - loss: 0.0837 - acc: 0.9751 - val_loss: 0.0633 - val_acc: 0.9821\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0562 - acc: 0.9829 - val_loss: 0.0453 - val_acc: 0.9871\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.0453 - acc: 0.9866 - val_loss: 0.0525 - val_acc: 0.9833\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0341 - acc: 0.9898 - val_loss: 0.0469 - val_acc: 0.9869\n",
      "Epoch 00005: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 6s 171us/step - loss: 0.3534 - acc: 0.8921 - val_loss: 0.0915 - val_acc: 0.9710\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.0850 - acc: 0.9740 - val_loss: 0.0634 - val_acc: 0.9807\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.0573 - acc: 0.9834 - val_loss: 0.0462 - val_acc: 0.9852\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0433 - acc: 0.9870 - val_loss: 0.0445 - val_acc: 0.9867\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0348 - acc: 0.9893 - val_loss: 0.0430 - val_acc: 0.9883\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0295 - acc: 0.9914 - val_loss: 0.0418 - val_acc: 0.9893\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0239 - acc: 0.9925 - val_loss: 0.0412 - val_acc: 0.9890\n",
      "Epoch 00007: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 7s 173us/step - loss: 0.3461 - acc: 0.8928 - val_loss: 0.0979 - val_acc: 0.9702\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 2s 64us/step - loss: 0.0964 - acc: 0.9708 - val_loss: 0.0640 - val_acc: 0.9800\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.0619 - acc: 0.9804 - val_loss: 0.0604 - val_acc: 0.9812\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.0496 - acc: 0.9843 - val_loss: 0.0555 - val_acc: 0.9838\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0397 - acc: 0.9876 - val_loss: 0.0505 - val_acc: 0.9860\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.0306 - acc: 0.9899 - val_loss: 0.0446 - val_acc: 0.9879\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.0269 - acc: 0.9911 - val_loss: 0.0456 - val_acc: 0.9876\n",
      "Epoch 8/10\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0225 - acc: 0.9930 - val_loss: 0.0466 - val_acc: 0.9871\n",
      "Epoch 00008: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 6s 172us/step - loss: 0.3675 - acc: 0.8858 - val_loss: 0.0990 - val_acc: 0.9714\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 2s 65us/step - loss: 0.0926 - acc: 0.9715 - val_loss: 0.0622 - val_acc: 0.9800\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.0612 - acc: 0.9811 - val_loss: 0.0504 - val_acc: 0.9850\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.0451 - acc: 0.9861 - val_loss: 0.0474 - val_acc: 0.9855\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.0351 - acc: 0.9892 - val_loss: 0.0489 - val_acc: 0.9857\n",
      "Epoch 00005: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 7s 176us/step - loss: 0.4022 - acc: 0.8767 - val_loss: 0.0996 - val_acc: 0.9686\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 2s 64us/step - loss: 0.0908 - acc: 0.9724 - val_loss: 0.0601 - val_acc: 0.9836\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 2s 64us/step - loss: 0.0587 - acc: 0.9819 - val_loss: 0.0475 - val_acc: 0.9869\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0454 - acc: 0.9860 - val_loss: 0.0531 - val_acc: 0.9852\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.0350 - acc: 0.9888 - val_loss: 0.0478 - val_acc: 0.9879\n",
      "Epoch 00005: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 7s 177us/step - loss: 0.3508 - acc: 0.8921 - val_loss: 0.0982 - val_acc: 0.9695\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 2s 64us/step - loss: 0.0897 - acc: 0.9731 - val_loss: 0.0655 - val_acc: 0.9802\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 2s 64us/step - loss: 0.0604 - acc: 0.9812 - val_loss: 0.0561 - val_acc: 0.9829\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 2s 64us/step - loss: 0.0436 - acc: 0.9866 - val_loss: 0.0492 - val_acc: 0.9869\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.0360 - acc: 0.9891 - val_loss: 0.0433 - val_acc: 0.9886\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 2s 64us/step - loss: 0.0313 - acc: 0.9899 - val_loss: 0.0481 - val_acc: 0.9864\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 2s 64us/step - loss: 0.0263 - acc: 0.9921 - val_loss: 0.0476 - val_acc: 0.9881\n",
      "Epoch 00007: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 7s 174us/step - loss: 0.3668 - acc: 0.8871 - val_loss: 0.1045 - val_acc: 0.9681\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 2s 64us/step - loss: 0.0946 - acc: 0.9715 - val_loss: 0.0727 - val_acc: 0.9776\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37800/37800 [==============================] - 2s 64us/step - loss: 0.0631 - acc: 0.9808 - val_loss: 0.0588 - val_acc: 0.9831\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 2s 65us/step - loss: 0.0461 - acc: 0.9856 - val_loss: 0.0452 - val_acc: 0.9855\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 2s 64us/step - loss: 0.0365 - acc: 0.9883 - val_loss: 0.0519 - val_acc: 0.9862\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 2s 65us/step - loss: 0.0288 - acc: 0.9909 - val_loss: 0.0448 - val_acc: 0.9876\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.0270 - acc: 0.9909 - val_loss: 0.0447 - val_acc: 0.9864\n",
      "Epoch 8/10\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0241 - acc: 0.9927 - val_loss: 0.0402 - val_acc: 0.9895\n",
      "Epoch 9/10\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.0166 - acc: 0.9947 - val_loss: 0.0439 - val_acc: 0.9900\n",
      "Epoch 10/10\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0165 - acc: 0.9946 - val_loss: 0.0427 - val_acc: 0.9876\n",
      "Epoch 00010: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 7s 173us/step - loss: 0.3594 - acc: 0.8936 - val_loss: 0.1024 - val_acc: 0.9695\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.0911 - acc: 0.9720 - val_loss: 0.0549 - val_acc: 0.9824\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 2s 65us/step - loss: 0.0591 - acc: 0.9816 - val_loss: 0.0505 - val_acc: 0.9850\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.0464 - acc: 0.9856 - val_loss: 0.0499 - val_acc: 0.9833\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 2s 64us/step - loss: 0.0384 - acc: 0.9880 - val_loss: 0.0384 - val_acc: 0.9893\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 2s 64us/step - loss: 0.0323 - acc: 0.9903 - val_loss: 0.0388 - val_acc: 0.9876\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 2s 64us/step - loss: 0.0246 - acc: 0.9920 - val_loss: 0.0395 - val_acc: 0.9893\n",
      "Epoch 00007: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 7s 183us/step - loss: 0.3895 - acc: 0.8795 - val_loss: 0.0970 - val_acc: 0.9705\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 2s 65us/step - loss: 0.0885 - acc: 0.9728 - val_loss: 0.0640 - val_acc: 0.9798\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.0597 - acc: 0.9817 - val_loss: 0.0659 - val_acc: 0.9795\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 2s 64us/step - loss: 0.0457 - acc: 0.9862 - val_loss: 0.0484 - val_acc: 0.9848\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.0368 - acc: 0.9889 - val_loss: 0.0479 - val_acc: 0.9862\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0287 - acc: 0.9911 - val_loss: 0.0424 - val_acc: 0.9876\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.0233 - acc: 0.9928 - val_loss: 0.0417 - val_acc: 0.9888\n",
      "Epoch 8/10\n",
      "37800/37800 [==============================] - 2s 64us/step - loss: 0.0234 - acc: 0.9928 - val_loss: 0.0511 - val_acc: 0.9852\n",
      "Epoch 9/10\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.0206 - acc: 0.9936 - val_loss: 0.0477 - val_acc: 0.9879\n",
      "Epoch 00009: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 8s 203us/step - loss: 0.3810 - acc: 0.8824 - val_loss: 0.0973 - val_acc: 0.9690\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 2s 64us/step - loss: 0.0900 - acc: 0.9727 - val_loss: 0.0639 - val_acc: 0.9798\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 2s 64us/step - loss: 0.0596 - acc: 0.9821 - val_loss: 0.0593 - val_acc: 0.9826\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.0453 - acc: 0.9861 - val_loss: 0.0433 - val_acc: 0.9869\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.0364 - acc: 0.9883 - val_loss: 0.0444 - val_acc: 0.9879\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.0299 - acc: 0.9906 - val_loss: 0.0508 - val_acc: 0.9857\n",
      "Epoch 00006: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 7s 183us/step - loss: 0.3574 - acc: 0.8900 - val_loss: 0.0971 - val_acc: 0.9669\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 2s 65us/step - loss: 0.0925 - acc: 0.9715 - val_loss: 0.0837 - val_acc: 0.9755\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 2s 66us/step - loss: 0.0654 - acc: 0.9790 - val_loss: 0.0612 - val_acc: 0.9795\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.0478 - acc: 0.9854 - val_loss: 0.0498 - val_acc: 0.9848\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 2s 65us/step - loss: 0.0356 - acc: 0.9890 - val_loss: 0.0468 - val_acc: 0.9871\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 2s 65us/step - loss: 0.0303 - acc: 0.9906 - val_loss: 0.0491 - val_acc: 0.9867\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 2s 64us/step - loss: 0.0264 - acc: 0.9917 - val_loss: 0.0445 - val_acc: 0.9876\n",
      "Epoch 00007: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 7s 181us/step - loss: 0.3594 - acc: 0.8892 - val_loss: 0.0954 - val_acc: 0.9726\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 2s 65us/step - loss: 0.0939 - acc: 0.9714 - val_loss: 0.0652 - val_acc: 0.9802\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 2s 65us/step - loss: 0.0619 - acc: 0.9808 - val_loss: 0.0472 - val_acc: 0.9869\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 2s 65us/step - loss: 0.0476 - acc: 0.9852 - val_loss: 0.0564 - val_acc: 0.9838\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 2s 65us/step - loss: 0.0384 - acc: 0.9881 - val_loss: 0.0488 - val_acc: 0.9857\n",
      "Epoch 00005: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 7s 185us/step - loss: 0.3384 - acc: 0.8943 - val_loss: 0.1007 - val_acc: 0.9693\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 2s 66us/step - loss: 0.0928 - acc: 0.9718 - val_loss: 0.0663 - val_acc: 0.9790\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 2s 65us/step - loss: 0.0625 - acc: 0.9805 - val_loss: 0.0572 - val_acc: 0.9810\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 66us/step - loss: 0.0493 - acc: 0.9851 - val_loss: 0.0513 - val_acc: 0.9869\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 2s 65us/step - loss: 0.0388 - acc: 0.9875 - val_loss: 0.0505 - val_acc: 0.9852\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 2s 65us/step - loss: 0.0326 - acc: 0.9896 - val_loss: 0.0444 - val_acc: 0.9867\n",
      "Epoch 00006: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 7s 189us/step - loss: 0.3600 - acc: 0.8914 - val_loss: 0.0940 - val_acc: 0.9721\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 2s 65us/step - loss: 0.0810 - acc: 0.9741 - val_loss: 0.0595 - val_acc: 0.9800\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 67us/step - loss: 0.0580 - acc: 0.9821 - val_loss: 0.0559 - val_acc: 0.9817\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 2s 64us/step - loss: 0.0456 - acc: 0.9858 - val_loss: 0.0444 - val_acc: 0.9864\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 2s 66us/step - loss: 0.0337 - acc: 0.9893 - val_loss: 0.0424 - val_acc: 0.9876\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 2s 64us/step - loss: 0.0300 - acc: 0.9904 - val_loss: 0.0421 - val_acc: 0.9879\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 3s 67us/step - loss: 0.0234 - acc: 0.9925 - val_loss: 0.0467 - val_acc: 0.9857\n",
      "Epoch 00007: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37800/37800 [==============================] - 7s 191us/step - loss: 0.3652 - acc: 0.8898 - val_loss: 0.1000 - val_acc: 0.9688\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 67us/step - loss: 0.0879 - acc: 0.9735 - val_loss: 0.0642 - val_acc: 0.9800\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 2s 65us/step - loss: 0.0592 - acc: 0.9816 - val_loss: 0.0535 - val_acc: 0.9836\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 2s 65us/step - loss: 0.0445 - acc: 0.9860 - val_loss: 0.0464 - val_acc: 0.9871\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 2s 65us/step - loss: 0.0362 - acc: 0.9889 - val_loss: 0.0447 - val_acc: 0.9886\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 67us/step - loss: 0.0310 - acc: 0.9902 - val_loss: 0.0422 - val_acc: 0.9895\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.0242 - acc: 0.9920 - val_loss: 0.0456 - val_acc: 0.9876\n",
      "Epoch 00007: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 7s 194us/step - loss: 0.3452 - acc: 0.8942 - val_loss: 0.0927 - val_acc: 0.9714\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 66us/step - loss: 0.0798 - acc: 0.9763 - val_loss: 0.0575 - val_acc: 0.9829\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 2s 65us/step - loss: 0.0559 - acc: 0.9825 - val_loss: 0.0490 - val_acc: 0.9864\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 68us/step - loss: 0.0429 - acc: 0.9864 - val_loss: 0.0451 - val_acc: 0.9864\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 2s 66us/step - loss: 0.0349 - acc: 0.9895 - val_loss: 0.0394 - val_acc: 0.9890\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 2s 65us/step - loss: 0.0283 - acc: 0.9910 - val_loss: 0.0432 - val_acc: 0.9867\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 2s 64us/step - loss: 0.0223 - acc: 0.9929 - val_loss: 0.0418 - val_acc: 0.9898\n",
      "Epoch 00007: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 7s 196us/step - loss: 0.3363 - acc: 0.8954 - val_loss: 0.1022 - val_acc: 0.9660\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 67us/step - loss: 0.0874 - acc: 0.9743 - val_loss: 0.0673 - val_acc: 0.9814\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 67us/step - loss: 0.0597 - acc: 0.9813 - val_loss: 0.0564 - val_acc: 0.9831\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 67us/step - loss: 0.0457 - acc: 0.9860 - val_loss: 0.0476 - val_acc: 0.9852\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 2s 65us/step - loss: 0.0360 - acc: 0.9883 - val_loss: 0.0474 - val_acc: 0.9848\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 2s 65us/step - loss: 0.0293 - acc: 0.9907 - val_loss: 0.0454 - val_acc: 0.9864\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 2s 65us/step - loss: 0.0238 - acc: 0.9924 - val_loss: 0.0531 - val_acc: 0.9852\n",
      "Epoch 8/10\n",
      "37800/37800 [==============================] - 2s 65us/step - loss: 0.0236 - acc: 0.9922 - val_loss: 0.0477 - val_acc: 0.9886\n",
      "Epoch 9/10\n",
      "37800/37800 [==============================] - 2s 64us/step - loss: 0.0209 - acc: 0.9935 - val_loss: 0.0475 - val_acc: 0.9879\n",
      "Epoch 10/10\n",
      "37800/37800 [==============================] - 2s 64us/step - loss: 0.0158 - acc: 0.9947 - val_loss: 0.0555 - val_acc: 0.9879\n",
      "Epoch 00010: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 7s 197us/step - loss: 0.3480 - acc: 0.8947 - val_loss: 0.0932 - val_acc: 0.9700\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 66us/step - loss: 0.0872 - acc: 0.9730 - val_loss: 0.0588 - val_acc: 0.9812\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 67us/step - loss: 0.0592 - acc: 0.9830 - val_loss: 0.0495 - val_acc: 0.9845\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 2s 65us/step - loss: 0.0437 - acc: 0.9870 - val_loss: 0.0522 - val_acc: 0.9831\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 2s 65us/step - loss: 0.0361 - acc: 0.9881 - val_loss: 0.0428 - val_acc: 0.9888\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 2s 65us/step - loss: 0.0276 - acc: 0.9906 - val_loss: 0.0560 - val_acc: 0.9867\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 2s 64us/step - loss: 0.0231 - acc: 0.9922 - val_loss: 0.0481 - val_acc: 0.9881\n",
      "Epoch 00007: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 8s 200us/step - loss: 0.3467 - acc: 0.8934 - val_loss: 0.1046 - val_acc: 0.9674\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 67us/step - loss: 0.0874 - acc: 0.9727 - val_loss: 0.0641 - val_acc: 0.9805\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 67us/step - loss: 0.0585 - acc: 0.9821 - val_loss: 0.0647 - val_acc: 0.9798\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 67us/step - loss: 0.0448 - acc: 0.9862 - val_loss: 0.0461 - val_acc: 0.9874\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 68us/step - loss: 0.0365 - acc: 0.9883 - val_loss: 0.0481 - val_acc: 0.9867\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 2s 65us/step - loss: 0.0304 - acc: 0.9904 - val_loss: 0.0471 - val_acc: 0.9874\n",
      "Epoch 00006: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 8s 199us/step - loss: 0.3512 - acc: 0.8909 - val_loss: 0.0929 - val_acc: 0.9717\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 66us/step - loss: 0.0914 - acc: 0.9730 - val_loss: 0.0630 - val_acc: 0.9829\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 66us/step - loss: 0.0628 - acc: 0.9807 - val_loss: 0.0567 - val_acc: 0.9831\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 66us/step - loss: 0.0499 - acc: 0.9845 - val_loss: 0.0557 - val_acc: 0.9831\n",
      "Epoch 00004: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 8s 203us/step - loss: 0.4068 - acc: 0.8756 - val_loss: 0.1054 - val_acc: 0.9657\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 67us/step - loss: 0.0954 - acc: 0.9717 - val_loss: 0.0761 - val_acc: 0.9783\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 68us/step - loss: 0.0655 - acc: 0.9800 - val_loss: 0.0570 - val_acc: 0.9829\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 2s 66us/step - loss: 0.0479 - acc: 0.9851 - val_loss: 0.0466 - val_acc: 0.9864\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 2s 66us/step - loss: 0.0381 - acc: 0.9877 - val_loss: 0.0447 - val_acc: 0.9879\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 68us/step - loss: 0.0306 - acc: 0.9907 - val_loss: 0.0410 - val_acc: 0.9879\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 3s 67us/step - loss: 0.0259 - acc: 0.9916 - val_loss: 0.0407 - val_acc: 0.9876\n",
      "Epoch 00007: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 8s 202us/step - loss: 0.3391 - acc: 0.8946 - val_loss: 0.1074 - val_acc: 0.9674\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 67us/step - loss: 0.0862 - acc: 0.9736 - val_loss: 0.0606 - val_acc: 0.9814\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 66us/step - loss: 0.0596 - acc: 0.9815 - val_loss: 0.0584 - val_acc: 0.9829\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 2s 66us/step - loss: 0.0469 - acc: 0.9854 - val_loss: 0.0577 - val_acc: 0.9824\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 2s 66us/step - loss: 0.0369 - acc: 0.9885 - val_loss: 0.0509 - val_acc: 0.9860\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 67us/step - loss: 0.0316 - acc: 0.9896 - val_loss: 0.0421 - val_acc: 0.9898\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 2s 66us/step - loss: 0.0266 - acc: 0.9916 - val_loss: 0.0431 - val_acc: 0.9871\n",
      "Epoch 8/10\n",
      "37800/37800 [==============================] - 2s 65us/step - loss: 0.0216 - acc: 0.9931 - val_loss: 0.0520 - val_acc: 0.9876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00008: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 8s 209us/step - loss: 0.3629 - acc: 0.8888 - val_loss: 0.1015 - val_acc: 0.9679\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 67us/step - loss: 0.0917 - acc: 0.9722 - val_loss: 0.0808 - val_acc: 0.9740\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 67us/step - loss: 0.0627 - acc: 0.9809 - val_loss: 0.0562 - val_acc: 0.9829\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 68us/step - loss: 0.0442 - acc: 0.9865 - val_loss: 0.0497 - val_acc: 0.9857\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 68us/step - loss: 0.0357 - acc: 0.9887 - val_loss: 0.0497 - val_acc: 0.9845\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 67us/step - loss: 0.0303 - acc: 0.9899 - val_loss: 0.0462 - val_acc: 0.9879\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 2s 66us/step - loss: 0.0263 - acc: 0.9914 - val_loss: 0.0463 - val_acc: 0.9879\n",
      "Epoch 8/10\n",
      "37800/37800 [==============================] - 2s 66us/step - loss: 0.0214 - acc: 0.9928 - val_loss: 0.0475 - val_acc: 0.9860\n",
      "Epoch 00008: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 8s 207us/step - loss: 0.3584 - acc: 0.8921 - val_loss: 0.0878 - val_acc: 0.9700\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 67us/step - loss: 0.0843 - acc: 0.9747 - val_loss: 0.0710 - val_acc: 0.9795\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 68us/step - loss: 0.0567 - acc: 0.9823 - val_loss: 0.0512 - val_acc: 0.9840\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 67us/step - loss: 0.0445 - acc: 0.9861 - val_loss: 0.0439 - val_acc: 0.9876\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 68us/step - loss: 0.0341 - acc: 0.9890 - val_loss: 0.0447 - val_acc: 0.9876\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 68us/step - loss: 0.0287 - acc: 0.9910 - val_loss: 0.0443 - val_acc: 0.9867\n",
      "Epoch 00006: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 8s 208us/step - loss: 0.3447 - acc: 0.8974 - val_loss: 0.0942 - val_acc: 0.9681\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 68us/step - loss: 0.0945 - acc: 0.9718 - val_loss: 0.0602 - val_acc: 0.9829\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 67us/step - loss: 0.0617 - acc: 0.9807 - val_loss: 0.0543 - val_acc: 0.9829\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 67us/step - loss: 0.0474 - acc: 0.9847 - val_loss: 0.0528 - val_acc: 0.9857\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 67us/step - loss: 0.0360 - acc: 0.9887 - val_loss: 0.0497 - val_acc: 0.9848\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 67us/step - loss: 0.0307 - acc: 0.9904 - val_loss: 0.0482 - val_acc: 0.9874\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 3s 67us/step - loss: 0.0265 - acc: 0.9917 - val_loss: 0.0469 - val_acc: 0.9864\n",
      "Epoch 8/10\n",
      "37800/37800 [==============================] - 3s 67us/step - loss: 0.0207 - acc: 0.9929 - val_loss: 0.0484 - val_acc: 0.9864\n",
      "Epoch 00008: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 9s 235us/step - loss: 0.3609 - acc: 0.8872 - val_loss: 0.0943 - val_acc: 0.9698\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 67us/step - loss: 0.0892 - acc: 0.9737 - val_loss: 0.0620 - val_acc: 0.9800\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 68us/step - loss: 0.0594 - acc: 0.9824 - val_loss: 0.0521 - val_acc: 0.9838\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 68us/step - loss: 0.0448 - acc: 0.9860 - val_loss: 0.0485 - val_acc: 0.9871\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 67us/step - loss: 0.0376 - acc: 0.9878 - val_loss: 0.0429 - val_acc: 0.9869\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 67us/step - loss: 0.0305 - acc: 0.9901 - val_loss: 0.0536 - val_acc: 0.9838\n",
      "Epoch 00006: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 8s 215us/step - loss: 0.3846 - acc: 0.8804 - val_loss: 0.1276 - val_acc: 0.9555\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 67us/step - loss: 0.1025 - acc: 0.9692 - val_loss: 0.0670 - val_acc: 0.9798\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 67us/step - loss: 0.0679 - acc: 0.9792 - val_loss: 0.0580 - val_acc: 0.9824\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 68us/step - loss: 0.0512 - acc: 0.9837 - val_loss: 0.0553 - val_acc: 0.9848\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 66us/step - loss: 0.0377 - acc: 0.9885 - val_loss: 0.0515 - val_acc: 0.9850\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 68us/step - loss: 0.0334 - acc: 0.9888 - val_loss: 0.0573 - val_acc: 0.9850\n",
      "Epoch 00006: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 8s 215us/step - loss: 0.3440 - acc: 0.8937 - val_loss: 0.0969 - val_acc: 0.9686\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 68us/step - loss: 0.0896 - acc: 0.9726 - val_loss: 0.0590 - val_acc: 0.9821\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 69us/step - loss: 0.0592 - acc: 0.9818 - val_loss: 0.0534 - val_acc: 0.9819\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 69us/step - loss: 0.0445 - acc: 0.9864 - val_loss: 0.0449 - val_acc: 0.9862\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 67us/step - loss: 0.0354 - acc: 0.9895 - val_loss: 0.0551 - val_acc: 0.9845\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 66us/step - loss: 0.0292 - acc: 0.9908 - val_loss: 0.0492 - val_acc: 0.9864\n",
      "Epoch 00006: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 8s 221us/step - loss: 0.3581 - acc: 0.8887 - val_loss: 0.0902 - val_acc: 0.9738\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 69us/step - loss: 0.0929 - acc: 0.9716 - val_loss: 0.0672 - val_acc: 0.9790\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 68us/step - loss: 0.0641 - acc: 0.9804 - val_loss: 0.0502 - val_acc: 0.9836\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 71us/step - loss: 0.0469 - acc: 0.9853 - val_loss: 0.0495 - val_acc: 0.9855\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 68us/step - loss: 0.0402 - acc: 0.9875 - val_loss: 0.0536 - val_acc: 0.9848\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 68us/step - loss: 0.0306 - acc: 0.9907 - val_loss: 0.0412 - val_acc: 0.9874\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 3s 67us/step - loss: 0.0268 - acc: 0.9911 - val_loss: 0.0459 - val_acc: 0.9855\n",
      "Epoch 8/10\n",
      "37800/37800 [==============================] - 2s 66us/step - loss: 0.0227 - acc: 0.9929 - val_loss: 0.0434 - val_acc: 0.9876\n",
      "Epoch 00008: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 8s 214us/step - loss: 0.3703 - acc: 0.8852 - val_loss: 0.1002 - val_acc: 0.9688\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 68us/step - loss: 0.0930 - acc: 0.9717 - val_loss: 0.0705 - val_acc: 0.9802\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 69us/step - loss: 0.0599 - acc: 0.9821 - val_loss: 0.0491 - val_acc: 0.9860\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 68us/step - loss: 0.0432 - acc: 0.9866 - val_loss: 0.0470 - val_acc: 0.9867\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 70us/step - loss: 0.0369 - acc: 0.9879 - val_loss: 0.0491 - val_acc: 0.9876\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 68us/step - loss: 0.0287 - acc: 0.9906 - val_loss: 0.0499 - val_acc: 0.9840\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 3s 67us/step - loss: 0.0241 - acc: 0.9920 - val_loss: 0.0472 - val_acc: 0.9869\n",
      "Epoch 00007: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37800/37800 [==============================] - 8s 223us/step - loss: 0.3739 - acc: 0.8852 - val_loss: 0.1022 - val_acc: 0.9688\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 69us/step - loss: 0.0964 - acc: 0.9710 - val_loss: 0.0677 - val_acc: 0.9800\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 69us/step - loss: 0.0618 - acc: 0.9817 - val_loss: 0.0559 - val_acc: 0.9821\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 69us/step - loss: 0.0467 - acc: 0.9852 - val_loss: 0.0553 - val_acc: 0.9840\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 68us/step - loss: 0.0391 - acc: 0.9877 - val_loss: 0.0524 - val_acc: 0.9829\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 67us/step - loss: 0.0291 - acc: 0.9914 - val_loss: 0.0504 - val_acc: 0.9895\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 3s 69us/step - loss: 0.0247 - acc: 0.9919 - val_loss: 0.0497 - val_acc: 0.9874\n",
      "Epoch 8/10\n",
      "37800/37800 [==============================] - 3s 66us/step - loss: 0.0217 - acc: 0.9928 - val_loss: 0.0456 - val_acc: 0.9886\n",
      "Epoch 00008: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 8s 216us/step - loss: 0.3482 - acc: 0.8920 - val_loss: 0.1002 - val_acc: 0.9712\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 70us/step - loss: 0.0909 - acc: 0.9718 - val_loss: 0.0857 - val_acc: 0.9733\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 69us/step - loss: 0.0636 - acc: 0.9806 - val_loss: 0.0590 - val_acc: 0.9838\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 69us/step - loss: 0.0455 - acc: 0.9859 - val_loss: 0.0534 - val_acc: 0.9840\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 68us/step - loss: 0.0378 - acc: 0.9877 - val_loss: 0.0473 - val_acc: 0.9855\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 67us/step - loss: 0.0326 - acc: 0.9899 - val_loss: 0.0477 - val_acc: 0.9876\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 3s 69us/step - loss: 0.0249 - acc: 0.9923 - val_loss: 0.0488 - val_acc: 0.9869\n",
      "Epoch 8/10\n",
      "37800/37800 [==============================] - 3s 68us/step - loss: 0.0229 - acc: 0.9925 - val_loss: 0.0453 - val_acc: 0.9895\n",
      "Epoch 9/10\n",
      "37800/37800 [==============================] - 3s 67us/step - loss: 0.0219 - acc: 0.9928 - val_loss: 0.0484 - val_acc: 0.9864\n",
      "Epoch 10/10\n",
      "37800/37800 [==============================] - 3s 68us/step - loss: 0.0152 - acc: 0.9954 - val_loss: 0.0472 - val_acc: 0.9862\n",
      "Epoch 00010: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 9s 227us/step - loss: 0.3645 - acc: 0.8881 - val_loss: 0.1094 - val_acc: 0.9662\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 71us/step - loss: 0.0956 - acc: 0.9703 - val_loss: 0.0636 - val_acc: 0.9798\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 70us/step - loss: 0.0638 - acc: 0.9810 - val_loss: 0.0489 - val_acc: 0.9826\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 70us/step - loss: 0.0486 - acc: 0.9846 - val_loss: 0.0454 - val_acc: 0.9867\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 69us/step - loss: 0.0378 - acc: 0.9881 - val_loss: 0.0497 - val_acc: 0.9888\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 68us/step - loss: 0.0294 - acc: 0.9912 - val_loss: 0.0500 - val_acc: 0.9860\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 3s 69us/step - loss: 0.0285 - acc: 0.9906 - val_loss: 0.0515 - val_acc: 0.9855\n",
      "Epoch 00007: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 8s 219us/step - loss: 0.3322 - acc: 0.8958 - val_loss: 0.0906 - val_acc: 0.9721\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 69us/step - loss: 0.0866 - acc: 0.9731 - val_loss: 0.0578 - val_acc: 0.9814\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 69us/step - loss: 0.0591 - acc: 0.9816 - val_loss: 0.0508 - val_acc: 0.9843\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 69us/step - loss: 0.0433 - acc: 0.9860 - val_loss: 0.0456 - val_acc: 0.9864\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 69us/step - loss: 0.0357 - acc: 0.9891 - val_loss: 0.0522 - val_acc: 0.9850\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 67us/step - loss: 0.0301 - acc: 0.9904 - val_loss: 0.0478 - val_acc: 0.9855\n",
      "Epoch 00006: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 8s 223us/step - loss: 0.3392 - acc: 0.8989 - val_loss: 0.0931 - val_acc: 0.9707\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 72us/step - loss: 0.0862 - acc: 0.9735 - val_loss: 0.0606 - val_acc: 0.9800\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 69us/step - loss: 0.0557 - acc: 0.9833 - val_loss: 0.0606 - val_acc: 0.9795\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 70us/step - loss: 0.0466 - acc: 0.9855 - val_loss: 0.0456 - val_acc: 0.9869\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 69us/step - loss: 0.0330 - acc: 0.9894 - val_loss: 0.0430 - val_acc: 0.9857\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 69us/step - loss: 0.0279 - acc: 0.9915 - val_loss: 0.0419 - val_acc: 0.9879\n",
      "Epoch 00006: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 8s 218us/step - loss: 0.3753 - acc: 0.8851 - val_loss: 0.1127 - val_acc: 0.9624\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 71us/step - loss: 0.0926 - acc: 0.9723 - val_loss: 0.0691 - val_acc: 0.9790\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 70us/step - loss: 0.0585 - acc: 0.9819 - val_loss: 0.0511 - val_acc: 0.9833\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 69us/step - loss: 0.0486 - acc: 0.9846 - val_loss: 0.0493 - val_acc: 0.9848\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 70us/step - loss: 0.0363 - acc: 0.9883 - val_loss: 0.0466 - val_acc: 0.9871\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 71us/step - loss: 0.0305 - acc: 0.9901 - val_loss: 0.0468 - val_acc: 0.9874\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 3s 68us/step - loss: 0.0267 - acc: 0.9916 - val_loss: 0.0548 - val_acc: 0.9864\n",
      "Epoch 00007: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 9s 225us/step - loss: 0.3365 - acc: 0.8981 - val_loss: 0.0964 - val_acc: 0.9724\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 70us/step - loss: 0.0910 - acc: 0.9725 - val_loss: 0.0634 - val_acc: 0.9819\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 70us/step - loss: 0.0601 - acc: 0.9816 - val_loss: 0.0506 - val_acc: 0.9848\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 70us/step - loss: 0.0434 - acc: 0.9862 - val_loss: 0.0518 - val_acc: 0.9840\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 70us/step - loss: 0.0367 - acc: 0.9881 - val_loss: 0.0480 - val_acc: 0.9855\n",
      "Epoch 00005: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 9s 237us/step - loss: 0.3743 - acc: 0.8825 - val_loss: 0.0925 - val_acc: 0.9700\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 70us/step - loss: 0.0893 - acc: 0.9724 - val_loss: 0.0644 - val_acc: 0.9807\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 70us/step - loss: 0.0604 - acc: 0.9823 - val_loss: 0.0581 - val_acc: 0.9833\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 69us/step - loss: 0.0441 - acc: 0.9863 - val_loss: 0.0486 - val_acc: 0.9867\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 70us/step - loss: 0.0360 - acc: 0.9881 - val_loss: 0.0469 - val_acc: 0.9867\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 69us/step - loss: 0.0295 - acc: 0.9906 - val_loss: 0.0476 - val_acc: 0.9860\n",
      "Epoch 00006: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37800/37800 [==============================] - 9s 241us/step - loss: 0.3384 - acc: 0.8944 - val_loss: 0.1029 - val_acc: 0.9669\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 71us/step - loss: 0.0880 - acc: 0.9735 - val_loss: 0.0619 - val_acc: 0.9793\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 70us/step - loss: 0.0587 - acc: 0.9815 - val_loss: 0.0601 - val_acc: 0.9810\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 70us/step - loss: 0.0462 - acc: 0.9863 - val_loss: 0.0421 - val_acc: 0.9871\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 69us/step - loss: 0.0337 - acc: 0.9892 - val_loss: 0.0450 - val_acc: 0.9867\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 70us/step - loss: 0.0290 - acc: 0.9906 - val_loss: 0.0480 - val_acc: 0.9871\n",
      "Epoch 00006: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 9s 242us/step - loss: 0.3499 - acc: 0.8922 - val_loss: 0.0938 - val_acc: 0.9702\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 70us/step - loss: 0.0893 - acc: 0.9737 - val_loss: 0.0562 - val_acc: 0.9843\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 71us/step - loss: 0.0596 - acc: 0.9813 - val_loss: 0.0522 - val_acc: 0.9857\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 71us/step - loss: 0.0459 - acc: 0.9860 - val_loss: 0.0415 - val_acc: 0.9857\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 69us/step - loss: 0.0356 - acc: 0.9888 - val_loss: 0.0410 - val_acc: 0.9869\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 71us/step - loss: 0.0283 - acc: 0.9908 - val_loss: 0.0440 - val_acc: 0.9874\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 3s 70us/step - loss: 0.0261 - acc: 0.9921 - val_loss: 0.0412 - val_acc: 0.9876\n",
      "Epoch 00007: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 9s 246us/step - loss: 0.3589 - acc: 0.8899 - val_loss: 0.0986 - val_acc: 0.9705\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 71us/step - loss: 0.0869 - acc: 0.9731 - val_loss: 0.0638 - val_acc: 0.9802\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 71us/step - loss: 0.0588 - acc: 0.9823 - val_loss: 0.0529 - val_acc: 0.9838\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.0454 - acc: 0.9859 - val_loss: 0.0460 - val_acc: 0.9857\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 70us/step - loss: 0.0348 - acc: 0.9896 - val_loss: 0.0457 - val_acc: 0.9876\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 70us/step - loss: 0.0300 - acc: 0.9897 - val_loss: 0.0476 - val_acc: 0.9881\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 3s 72us/step - loss: 0.0266 - acc: 0.9916 - val_loss: 0.0465 - val_acc: 0.9862\n",
      "Epoch 00007: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 9s 232us/step - loss: 0.3613 - acc: 0.8888 - val_loss: 0.0958 - val_acc: 0.9674\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 72us/step - loss: 0.0923 - acc: 0.9712 - val_loss: 0.0736 - val_acc: 0.9779\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 71us/step - loss: 0.0632 - acc: 0.9815 - val_loss: 0.0530 - val_acc: 0.9831\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 72us/step - loss: 0.0506 - acc: 0.9836 - val_loss: 0.0459 - val_acc: 0.9879\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 71us/step - loss: 0.0380 - acc: 0.9878 - val_loss: 0.0492 - val_acc: 0.9852\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 70us/step - loss: 0.0321 - acc: 0.9901 - val_loss: 0.0409 - val_acc: 0.9879\n",
      "Epoch 00006: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 9s 247us/step - loss: 0.3574 - acc: 0.8939 - val_loss: 0.1041 - val_acc: 0.9693\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 71us/step - loss: 0.0927 - acc: 0.9710 - val_loss: 0.0749 - val_acc: 0.9781\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 69us/step - loss: 0.0606 - acc: 0.9807 - val_loss: 0.0593 - val_acc: 0.9843\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 71us/step - loss: 0.0473 - acc: 0.9852 - val_loss: 0.0430 - val_acc: 0.9881\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 71us/step - loss: 0.0378 - acc: 0.9886 - val_loss: 0.0486 - val_acc: 0.9874\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 71us/step - loss: 0.0315 - acc: 0.9896 - val_loss: 0.0438 - val_acc: 0.9871\n",
      "Epoch 00006: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 10s 252us/step - loss: 0.3475 - acc: 0.8969 - val_loss: 0.1000 - val_acc: 0.9695\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 74us/step - loss: 0.0906 - acc: 0.9731 - val_loss: 0.0616 - val_acc: 0.9807\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 72us/step - loss: 0.0606 - acc: 0.9817 - val_loss: 0.0603 - val_acc: 0.9814\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 71us/step - loss: 0.0481 - acc: 0.9852 - val_loss: 0.0498 - val_acc: 0.9850\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.0366 - acc: 0.9887 - val_loss: 0.0527 - val_acc: 0.9848\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 71us/step - loss: 0.0293 - acc: 0.9906 - val_loss: 0.0453 - val_acc: 0.9876\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 3s 70us/step - loss: 0.0265 - acc: 0.9916 - val_loss: 0.0482 - val_acc: 0.9890\n",
      "Epoch 8/10\n",
      "37800/37800 [==============================] - 3s 69us/step - loss: 0.0204 - acc: 0.9929 - val_loss: 0.0570 - val_acc: 0.9874\n",
      "Epoch 9/10\n",
      "37800/37800 [==============================] - 3s 69us/step - loss: 0.0201 - acc: 0.9934 - val_loss: 0.0520 - val_acc: 0.9869\n",
      "Epoch 00009: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 9s 242us/step - loss: 0.3603 - acc: 0.8892 - val_loss: 0.0979 - val_acc: 0.9702\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 72us/step - loss: 0.0874 - acc: 0.9727 - val_loss: 0.0632 - val_acc: 0.9812\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 72us/step - loss: 0.0573 - acc: 0.9827 - val_loss: 0.0605 - val_acc: 0.9836\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 72us/step - loss: 0.0441 - acc: 0.9864 - val_loss: 0.0492 - val_acc: 0.9852\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 71us/step - loss: 0.0355 - acc: 0.9889 - val_loss: 0.0434 - val_acc: 0.9879\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 71us/step - loss: 0.0284 - acc: 0.9915 - val_loss: 0.0547 - val_acc: 0.9860\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 3s 71us/step - loss: 0.0250 - acc: 0.9923 - val_loss: 0.0466 - val_acc: 0.9874\n",
      "Epoch 00007: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 9s 234us/step - loss: 0.3411 - acc: 0.8911 - val_loss: 0.1085 - val_acc: 0.9667\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.0937 - acc: 0.9716 - val_loss: 0.0740 - val_acc: 0.9762\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.0641 - acc: 0.9798 - val_loss: 0.0566 - val_acc: 0.9819\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 71us/step - loss: 0.0482 - acc: 0.9847 - val_loss: 0.0462 - val_acc: 0.9857\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 72us/step - loss: 0.0384 - acc: 0.9873 - val_loss: 0.0443 - val_acc: 0.9883\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 70us/step - loss: 0.0294 - acc: 0.9908 - val_loss: 0.0494 - val_acc: 0.9845\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.0251 - acc: 0.9921 - val_loss: 0.0424 - val_acc: 0.9881\n",
      "Epoch 00007: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37800/37800 [==============================] - 10s 260us/step - loss: 0.3600 - acc: 0.8910 - val_loss: 0.0969 - val_acc: 0.9671\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.0862 - acc: 0.9738 - val_loss: 0.0611 - val_acc: 0.9807\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.0573 - acc: 0.9821 - val_loss: 0.0591 - val_acc: 0.9829\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.0449 - acc: 0.9858 - val_loss: 0.0498 - val_acc: 0.9876\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 72us/step - loss: 0.0335 - acc: 0.9897 - val_loss: 0.0441 - val_acc: 0.9871\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 72us/step - loss: 0.0295 - acc: 0.9908 - val_loss: 0.0433 - val_acc: 0.9879\n",
      "Epoch 00006: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 10s 257us/step - loss: 0.3969 - acc: 0.8763 - val_loss: 0.1025 - val_acc: 0.9667\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 74us/step - loss: 0.0922 - acc: 0.9708 - val_loss: 0.0684 - val_acc: 0.9779\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 72us/step - loss: 0.0619 - acc: 0.9811 - val_loss: 0.0590 - val_acc: 0.9838\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 71us/step - loss: 0.0478 - acc: 0.9848 - val_loss: 0.0549 - val_acc: 0.9836\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.0393 - acc: 0.9878 - val_loss: 0.0449 - val_acc: 0.9881\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.0318 - acc: 0.9904 - val_loss: 0.0474 - val_acc: 0.9850\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 3s 71us/step - loss: 0.0258 - acc: 0.9917 - val_loss: 0.0428 - val_acc: 0.9879\n",
      "Epoch 00007: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 9s 239us/step - loss: 0.3469 - acc: 0.8932 - val_loss: 0.1083 - val_acc: 0.9669\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 74us/step - loss: 0.0973 - acc: 0.9702 - val_loss: 0.0598 - val_acc: 0.9812\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.0646 - acc: 0.9811 - val_loss: 0.0496 - val_acc: 0.9845\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 72us/step - loss: 0.0475 - acc: 0.9854 - val_loss: 0.0482 - val_acc: 0.9864\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.0371 - acc: 0.9888 - val_loss: 0.0515 - val_acc: 0.9864\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 72us/step - loss: 0.0305 - acc: 0.9902 - val_loss: 0.0398 - val_acc: 0.9879\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.0261 - acc: 0.9923 - val_loss: 0.0520 - val_acc: 0.9857\n",
      "Epoch 8/10\n",
      "37800/37800 [==============================] - 3s 72us/step - loss: 0.0228 - acc: 0.9929 - val_loss: 0.0411 - val_acc: 0.9895\n",
      "Epoch 9/10\n",
      "37800/37800 [==============================] - 3s 72us/step - loss: 0.0195 - acc: 0.9938 - val_loss: 0.0489 - val_acc: 0.9874\n",
      "Epoch 10/10\n",
      "37800/37800 [==============================] - 3s 72us/step - loss: 0.0198 - acc: 0.9938 - val_loss: 0.0511 - val_acc: 0.9852\n",
      "Epoch 00010: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 10s 262us/step - loss: 0.3696 - acc: 0.8881 - val_loss: 0.0958 - val_acc: 0.9714\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 71us/step - loss: 0.0934 - acc: 0.9724 - val_loss: 0.0624 - val_acc: 0.9810\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 74us/step - loss: 0.0622 - acc: 0.9814 - val_loss: 0.0551 - val_acc: 0.9848\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.0475 - acc: 0.9854 - val_loss: 0.0463 - val_acc: 0.9850\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 74us/step - loss: 0.0374 - acc: 0.9886 - val_loss: 0.0573 - val_acc: 0.9833\n",
      "Epoch 00005: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 10s 267us/step - loss: 0.3508 - acc: 0.8908 - val_loss: 0.0867 - val_acc: 0.9740\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.0877 - acc: 0.9719 - val_loss: 0.0694 - val_acc: 0.9790\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.0608 - acc: 0.9812 - val_loss: 0.0568 - val_acc: 0.9824\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 74us/step - loss: 0.0473 - acc: 0.9860 - val_loss: 0.0514 - val_acc: 0.9862\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 72us/step - loss: 0.0352 - acc: 0.9890 - val_loss: 0.0397 - val_acc: 0.9898\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.0288 - acc: 0.9911 - val_loss: 0.0509 - val_acc: 0.9869\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 3s 71us/step - loss: 0.0245 - acc: 0.9926 - val_loss: 0.0498 - val_acc: 0.9879\n",
      "Epoch 00007: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 10s 266us/step - loss: 0.3472 - acc: 0.8926 - val_loss: 0.1085 - val_acc: 0.9688\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.0906 - acc: 0.9727 - val_loss: 0.0684 - val_acc: 0.9788\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 74us/step - loss: 0.0613 - acc: 0.9806 - val_loss: 0.0553 - val_acc: 0.9848\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 74us/step - loss: 0.0477 - acc: 0.9849 - val_loss: 0.0546 - val_acc: 0.9836\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 72us/step - loss: 0.0359 - acc: 0.9889 - val_loss: 0.0471 - val_acc: 0.9867\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 72us/step - loss: 0.0322 - acc: 0.9896 - val_loss: 0.0479 - val_acc: 0.9874\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 3s 72us/step - loss: 0.0268 - acc: 0.9914 - val_loss: 0.0455 - val_acc: 0.9886\n",
      "Epoch 8/10\n",
      "37800/37800 [==============================] - 3s 71us/step - loss: 0.0233 - acc: 0.9925 - val_loss: 0.0519 - val_acc: 0.9850\n",
      "Epoch 9/10\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.0185 - acc: 0.9940 - val_loss: 0.0492 - val_acc: 0.9864\n",
      "Epoch 00009: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 10s 268us/step - loss: 0.3569 - acc: 0.8894 - val_loss: 0.1079 - val_acc: 0.9643\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.0892 - acc: 0.9730 - val_loss: 0.0607 - val_acc: 0.9838\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.0595 - acc: 0.9811 - val_loss: 0.0508 - val_acc: 0.9855\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.0450 - acc: 0.9858 - val_loss: 0.0423 - val_acc: 0.9879\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 74us/step - loss: 0.0343 - acc: 0.9896 - val_loss: 0.0479 - val_acc: 0.9876\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 74us/step - loss: 0.0287 - acc: 0.9910 - val_loss: 0.0442 - val_acc: 0.9888\n",
      "Epoch 00006: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 9s 249us/step - loss: 0.3742 - acc: 0.8865 - val_loss: 0.0935 - val_acc: 0.9714\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 74us/step - loss: 0.0936 - acc: 0.9717 - val_loss: 0.0658 - val_acc: 0.9786\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.0630 - acc: 0.9804 - val_loss: 0.0577 - val_acc: 0.9819\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.0474 - acc: 0.9848 - val_loss: 0.0478 - val_acc: 0.9848\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.0389 - acc: 0.9880 - val_loss: 0.0444 - val_acc: 0.9857\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.0326 - acc: 0.9899 - val_loss: 0.0529 - val_acc: 0.9855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00006: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 10s 274us/step - loss: 0.3346 - acc: 0.8945 - val_loss: 0.0962 - val_acc: 0.9705\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 75us/step - loss: 0.0929 - acc: 0.9719 - val_loss: 0.0664 - val_acc: 0.9788\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 74us/step - loss: 0.0647 - acc: 0.9799 - val_loss: 0.0573 - val_acc: 0.9814\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.0493 - acc: 0.9848 - val_loss: 0.0522 - val_acc: 0.9855\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.0390 - acc: 0.9878 - val_loss: 0.0443 - val_acc: 0.9881\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.0313 - acc: 0.9902 - val_loss: 0.0506 - val_acc: 0.9874\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.0289 - acc: 0.9910 - val_loss: 0.0449 - val_acc: 0.9871\n",
      "Epoch 00007: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 10s 277us/step - loss: 0.3665 - acc: 0.8887 - val_loss: 0.1055 - val_acc: 0.9669\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 74us/step - loss: 0.0923 - acc: 0.9720 - val_loss: 0.0717 - val_acc: 0.9774\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.0620 - acc: 0.9810 - val_loss: 0.0627 - val_acc: 0.9819\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.0483 - acc: 0.9854 - val_loss: 0.0505 - val_acc: 0.9869\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 75us/step - loss: 0.0383 - acc: 0.9880 - val_loss: 0.0443 - val_acc: 0.9876\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.0308 - acc: 0.9907 - val_loss: 0.0474 - val_acc: 0.9874\n",
      "Epoch 00006: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 10s 277us/step - loss: 0.3436 - acc: 0.8922 - val_loss: 0.1044 - val_acc: 0.9674\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 74us/step - loss: 0.0924 - acc: 0.9720 - val_loss: 0.0722 - val_acc: 0.9779\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 75us/step - loss: 0.0610 - acc: 0.9817 - val_loss: 0.0563 - val_acc: 0.9836\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 74us/step - loss: 0.0465 - acc: 0.9856 - val_loss: 0.0530 - val_acc: 0.9857\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.0356 - acc: 0.9891 - val_loss: 0.0471 - val_acc: 0.9857\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 74us/step - loss: 0.0307 - acc: 0.9896 - val_loss: 0.0412 - val_acc: 0.9900\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 3s 74us/step - loss: 0.0256 - acc: 0.9919 - val_loss: 0.0469 - val_acc: 0.9898\n",
      "Epoch 8/10\n",
      "37800/37800 [==============================] - 3s 74us/step - loss: 0.0215 - acc: 0.9935 - val_loss: 0.0497 - val_acc: 0.9876\n",
      "Epoch 00008: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 11s 284us/step - loss: 0.3446 - acc: 0.8920 - val_loss: 0.0920 - val_acc: 0.9707\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 72us/step - loss: 0.0958 - acc: 0.9705 - val_loss: 0.0684 - val_acc: 0.9800\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 74us/step - loss: 0.0650 - acc: 0.9799 - val_loss: 0.0586 - val_acc: 0.9819\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 74us/step - loss: 0.0494 - acc: 0.9848 - val_loss: 0.0472 - val_acc: 0.9867\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 75us/step - loss: 0.0393 - acc: 0.9874 - val_loss: 0.0444 - val_acc: 0.9867\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.0296 - acc: 0.9907 - val_loss: 0.0521 - val_acc: 0.9860\n",
      "Epoch 00006: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 10s 254us/step - loss: 0.3395 - acc: 0.8942 - val_loss: 0.0999 - val_acc: 0.9674\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 75us/step - loss: 0.0953 - acc: 0.9700 - val_loss: 0.0719 - val_acc: 0.9769\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 75us/step - loss: 0.0622 - acc: 0.9803 - val_loss: 0.0457 - val_acc: 0.9860\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 75us/step - loss: 0.0470 - acc: 0.9857 - val_loss: 0.0396 - val_acc: 0.9867\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 74us/step - loss: 0.0377 - acc: 0.9884 - val_loss: 0.0490 - val_acc: 0.9852\n",
      "Epoch 00005: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 11s 283us/step - loss: 0.3375 - acc: 0.8959 - val_loss: 0.0945 - val_acc: 0.9681\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 74us/step - loss: 0.0854 - acc: 0.9747 - val_loss: 0.0589 - val_acc: 0.9826\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.0579 - acc: 0.9821 - val_loss: 0.0514 - val_acc: 0.9833\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 74us/step - loss: 0.0426 - acc: 0.9867 - val_loss: 0.0403 - val_acc: 0.9886\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.0363 - acc: 0.9887 - val_loss: 0.0495 - val_acc: 0.9845\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 74us/step - loss: 0.0285 - acc: 0.9909 - val_loss: 0.0461 - val_acc: 0.9857\n",
      "Epoch 00006: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 10s 256us/step - loss: 0.3506 - acc: 0.8960 - val_loss: 0.1026 - val_acc: 0.9688\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 75us/step - loss: 0.0858 - acc: 0.9739 - val_loss: 0.0617 - val_acc: 0.9831\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 74us/step - loss: 0.0570 - acc: 0.9824 - val_loss: 0.0502 - val_acc: 0.9848\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 75us/step - loss: 0.0428 - acc: 0.9862 - val_loss: 0.0398 - val_acc: 0.9881\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 75us/step - loss: 0.0356 - acc: 0.9894 - val_loss: 0.0432 - val_acc: 0.9869\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 74us/step - loss: 0.0301 - acc: 0.9911 - val_loss: 0.0407 - val_acc: 0.9881\n",
      "Epoch 00006: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 10s 262us/step - loss: 0.3497 - acc: 0.8926 - val_loss: 0.0974 - val_acc: 0.9662\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 76us/step - loss: 0.0881 - acc: 0.9734 - val_loss: 0.0580 - val_acc: 0.9817\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.0582 - acc: 0.9818 - val_loss: 0.0558 - val_acc: 0.9831\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 75us/step - loss: 0.0452 - acc: 0.9851 - val_loss: 0.0542 - val_acc: 0.9843\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.0357 - acc: 0.9893 - val_loss: 0.0546 - val_acc: 0.9848\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 74us/step - loss: 0.0326 - acc: 0.9902 - val_loss: 0.0437 - val_acc: 0.9869\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 3s 72us/step - loss: 0.0247 - acc: 0.9930 - val_loss: 0.0438 - val_acc: 0.9869\n",
      "Epoch 8/10\n",
      "37800/37800 [==============================] - 3s 74us/step - loss: 0.0217 - acc: 0.9933 - val_loss: 0.0451 - val_acc: 0.9876\n",
      "Epoch 00008: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 11s 289us/step - loss: 0.3909 - acc: 0.8794 - val_loss: 0.0857 - val_acc: 0.9750\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 75us/step - loss: 0.0862 - acc: 0.9740 - val_loss: 0.0598 - val_acc: 0.9821\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37800/37800 [==============================] - 3s 76us/step - loss: 0.0572 - acc: 0.9822 - val_loss: 0.0568 - val_acc: 0.9843\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 76us/step - loss: 0.0441 - acc: 0.9867 - val_loss: 0.0522 - val_acc: 0.9833\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 74us/step - loss: 0.0333 - acc: 0.9897 - val_loss: 0.0402 - val_acc: 0.9871\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.0306 - acc: 0.9906 - val_loss: 0.0403 - val_acc: 0.9883\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 3s 75us/step - loss: 0.0235 - acc: 0.9928 - val_loss: 0.0510 - val_acc: 0.9864\n",
      "Epoch 8/10\n",
      "37800/37800 [==============================] - 3s 74us/step - loss: 0.0189 - acc: 0.9937 - val_loss: 0.0395 - val_acc: 0.9888\n",
      "Epoch 00008: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 10s 266us/step - loss: 0.3475 - acc: 0.8957 - val_loss: 0.1073 - val_acc: 0.9648\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 74us/step - loss: 0.0904 - acc: 0.9727 - val_loss: 0.0776 - val_acc: 0.9743\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 75us/step - loss: 0.0578 - acc: 0.9822 - val_loss: 0.0499 - val_acc: 0.9843\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 75us/step - loss: 0.0425 - acc: 0.9868 - val_loss: 0.0548 - val_acc: 0.9845\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 74us/step - loss: 0.0351 - acc: 0.9888 - val_loss: 0.0433 - val_acc: 0.9876\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 74us/step - loss: 0.0276 - acc: 0.9912 - val_loss: 0.0432 - val_acc: 0.9876\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 3s 74us/step - loss: 0.0250 - acc: 0.9920 - val_loss: 0.0517 - val_acc: 0.9855\n",
      "Epoch 00007: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 11s 298us/step - loss: 0.3553 - acc: 0.8913 - val_loss: 0.0905 - val_acc: 0.9702\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 76us/step - loss: 0.0873 - acc: 0.9726 - val_loss: 0.0633 - val_acc: 0.9795\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 75us/step - loss: 0.0593 - acc: 0.9820 - val_loss: 0.0523 - val_acc: 0.9826\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 75us/step - loss: 0.0460 - acc: 0.9861 - val_loss: 0.0468 - val_acc: 0.9850\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 76us/step - loss: 0.0362 - acc: 0.9891 - val_loss: 0.0475 - val_acc: 0.9864\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 74us/step - loss: 0.0296 - acc: 0.9912 - val_loss: 0.0436 - val_acc: 0.9864\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 3s 75us/step - loss: 0.0237 - acc: 0.9928 - val_loss: 0.0433 - val_acc: 0.9888\n",
      "Epoch 8/10\n",
      "37800/37800 [==============================] - 3s 76us/step - loss: 0.0215 - acc: 0.9934 - val_loss: 0.0399 - val_acc: 0.9886\n",
      "Epoch 9/10\n",
      "37800/37800 [==============================] - 3s 74us/step - loss: 0.0182 - acc: 0.9944 - val_loss: 0.0528 - val_acc: 0.9886\n",
      "Epoch 00009: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 10s 270us/step - loss: 0.3357 - acc: 0.8978 - val_loss: 0.0950 - val_acc: 0.9707\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 75us/step - loss: 0.0889 - acc: 0.9728 - val_loss: 0.0716 - val_acc: 0.9786\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 75us/step - loss: 0.0606 - acc: 0.9813 - val_loss: 0.0455 - val_acc: 0.9860\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 77us/step - loss: 0.0434 - acc: 0.9866 - val_loss: 0.0502 - val_acc: 0.9840\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 76us/step - loss: 0.0377 - acc: 0.9889 - val_loss: 0.0445 - val_acc: 0.9869\n",
      "Epoch 00005: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 11s 296us/step - loss: 0.3616 - acc: 0.8881 - val_loss: 0.1017 - val_acc: 0.9676\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 76us/step - loss: 0.0905 - acc: 0.9728 - val_loss: 0.0678 - val_acc: 0.9795\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 76us/step - loss: 0.0613 - acc: 0.9815 - val_loss: 0.0508 - val_acc: 0.9845\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 76us/step - loss: 0.0465 - acc: 0.9859 - val_loss: 0.0589 - val_acc: 0.9843\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 75us/step - loss: 0.0355 - acc: 0.9889 - val_loss: 0.0541 - val_acc: 0.9833\n",
      "Epoch 00005: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 11s 298us/step - loss: 0.3334 - acc: 0.8979 - val_loss: 0.1032 - val_acc: 0.9679\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 75us/step - loss: 0.0919 - acc: 0.9723 - val_loss: 0.0650 - val_acc: 0.9774\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 75us/step - loss: 0.0612 - acc: 0.9815 - val_loss: 0.0550 - val_acc: 0.9831\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 75us/step - loss: 0.0464 - acc: 0.9854 - val_loss: 0.0463 - val_acc: 0.9852\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 74us/step - loss: 0.0377 - acc: 0.9882 - val_loss: 0.0490 - val_acc: 0.9869\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 75us/step - loss: 0.0300 - acc: 0.9904 - val_loss: 0.0443 - val_acc: 0.9883\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 3s 75us/step - loss: 0.0251 - acc: 0.9924 - val_loss: 0.0546 - val_acc: 0.9855\n",
      "Epoch 8/10\n",
      "37800/37800 [==============================] - 3s 74us/step - loss: 0.0222 - acc: 0.9929 - val_loss: 0.0460 - val_acc: 0.9890\n",
      "Epoch 00008: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 13s 336us/step - loss: 0.3688 - acc: 0.8872 - val_loss: 0.1031 - val_acc: 0.9674\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 75us/step - loss: 0.0937 - acc: 0.9726 - val_loss: 0.0655 - val_acc: 0.9800\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.0634 - acc: 0.9803 - val_loss: 0.0591 - val_acc: 0.9838\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 75us/step - loss: 0.0478 - acc: 0.9858 - val_loss: 0.0561 - val_acc: 0.9836\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 74us/step - loss: 0.0385 - acc: 0.9880 - val_loss: 0.0505 - val_acc: 0.9833\n",
      "Epoch 00005: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 11s 288us/step - loss: 0.3572 - acc: 0.8878 - val_loss: 0.0998 - val_acc: 0.9688\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 76us/step - loss: 0.0970 - acc: 0.9712 - val_loss: 0.0673 - val_acc: 0.9793\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 75us/step - loss: 0.0636 - acc: 0.9806 - val_loss: 0.0552 - val_acc: 0.9838\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 75us/step - loss: 0.0493 - acc: 0.9850 - val_loss: 0.0506 - val_acc: 0.9857\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 76us/step - loss: 0.0370 - acc: 0.9884 - val_loss: 0.0465 - val_acc: 0.9869\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 75us/step - loss: 0.0315 - acc: 0.9902 - val_loss: 0.0491 - val_acc: 0.9860\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 3s 74us/step - loss: 0.0259 - acc: 0.9914 - val_loss: 0.0455 - val_acc: 0.9864\n",
      "Epoch 00007: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 11s 279us/step - loss: 0.3564 - acc: 0.8892 - val_loss: 0.0956 - val_acc: 0.9700\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 76us/step - loss: 0.0913 - acc: 0.9722 - val_loss: 0.0762 - val_acc: 0.9771\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 76us/step - loss: 0.0591 - acc: 0.9820 - val_loss: 0.0531 - val_acc: 0.9836\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37800/37800 [==============================] - 3s 79us/step - loss: 0.0485 - acc: 0.9853 - val_loss: 0.0493 - val_acc: 0.9838\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 75us/step - loss: 0.0387 - acc: 0.9880 - val_loss: 0.0520 - val_acc: 0.9860\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 74us/step - loss: 0.0287 - acc: 0.9911 - val_loss: 0.0451 - val_acc: 0.9876\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 3s 75us/step - loss: 0.0266 - acc: 0.9917 - val_loss: 0.0460 - val_acc: 0.9855\n",
      "Epoch 8/10\n",
      "37800/37800 [==============================] - 3s 76us/step - loss: 0.0209 - acc: 0.9938 - val_loss: 0.0501 - val_acc: 0.9881\n",
      "Epoch 00008: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 11s 287us/step - loss: 0.3681 - acc: 0.8853 - val_loss: 0.1027 - val_acc: 0.9698\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 4s 100us/step - loss: 0.0899 - acc: 0.9722 - val_loss: 0.0582 - val_acc: 0.9812\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 80us/step - loss: 0.0600 - acc: 0.9815 - val_loss: 0.0513 - val_acc: 0.9838\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 83us/step - loss: 0.0450 - acc: 0.9861 - val_loss: 0.0540 - val_acc: 0.9852\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 4s 95us/step - loss: 0.0344 - acc: 0.9893 - val_loss: 0.0475 - val_acc: 0.9852\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 89us/step - loss: 0.0283 - acc: 0.9907 - val_loss: 0.0525 - val_acc: 0.9845\n",
      "Epoch 00006: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 12s 321us/step - loss: 0.4007 - acc: 0.8800 - val_loss: 0.1014 - val_acc: 0.9679\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 87us/step - loss: 0.0956 - acc: 0.9700 - val_loss: 0.0653 - val_acc: 0.9800\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 86us/step - loss: 0.0643 - acc: 0.9801 - val_loss: 0.0576 - val_acc: 0.9814\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 81us/step - loss: 0.0478 - acc: 0.9846 - val_loss: 0.0475 - val_acc: 0.9874\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 81us/step - loss: 0.0426 - acc: 0.9865 - val_loss: 0.0465 - val_acc: 0.9860\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 78us/step - loss: 0.0309 - acc: 0.9900 - val_loss: 0.0462 - val_acc: 0.9867\n",
      "Epoch 00006: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 12s 325us/step - loss: 0.3688 - acc: 0.8823 - val_loss: 0.1070 - val_acc: 0.9645\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 81us/step - loss: 0.0973 - acc: 0.9698 - val_loss: 0.0765 - val_acc: 0.9774\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 84us/step - loss: 0.0662 - acc: 0.9801 - val_loss: 0.0520 - val_acc: 0.9840\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 84us/step - loss: 0.0499 - acc: 0.9850 - val_loss: 0.0621 - val_acc: 0.9819\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 82us/step - loss: 0.0388 - acc: 0.9886 - val_loss: 0.0543 - val_acc: 0.9857\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 84us/step - loss: 0.0307 - acc: 0.9900 - val_loss: 0.0479 - val_acc: 0.9864\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 3s 81us/step - loss: 0.0278 - acc: 0.9910 - val_loss: 0.0526 - val_acc: 0.9862\n",
      "Epoch 00007: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 12s 325us/step - loss: 0.3840 - acc: 0.8842 - val_loss: 0.0865 - val_acc: 0.9702\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 83us/step - loss: 0.0874 - acc: 0.9733 - val_loss: 0.0659 - val_acc: 0.9795\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 82us/step - loss: 0.0623 - acc: 0.9804 - val_loss: 0.0532 - val_acc: 0.9831\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 84us/step - loss: 0.0482 - acc: 0.9854 - val_loss: 0.0462 - val_acc: 0.9867\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 86us/step - loss: 0.0382 - acc: 0.9883 - val_loss: 0.0408 - val_acc: 0.9874\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 85us/step - loss: 0.0305 - acc: 0.9904 - val_loss: 0.0413 - val_acc: 0.9886\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 3s 84us/step - loss: 0.0250 - acc: 0.9923 - val_loss: 0.0431 - val_acc: 0.9890\n",
      "Epoch 8/10\n",
      "37800/37800 [==============================] - 3s 81us/step - loss: 0.0231 - acc: 0.9930 - val_loss: 0.0344 - val_acc: 0.9888\n",
      "Epoch 00008: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 13s 334us/step - loss: 0.3307 - acc: 0.8985 - val_loss: 0.0825 - val_acc: 0.9738\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 85us/step - loss: 0.0850 - acc: 0.9746 - val_loss: 0.0601 - val_acc: 0.9810\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 85us/step - loss: 0.0570 - acc: 0.9825 - val_loss: 0.0535 - val_acc: 0.9855\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 84us/step - loss: 0.0440 - acc: 0.9864 - val_loss: 0.0429 - val_acc: 0.9864\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 84us/step - loss: 0.0350 - acc: 0.9885 - val_loss: 0.0457 - val_acc: 0.9852\n",
      "Epoch 00005: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 13s 338us/step - loss: 0.3384 - acc: 0.8939 - val_loss: 0.0946 - val_acc: 0.9714\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 85us/step - loss: 0.0885 - acc: 0.9727 - val_loss: 0.0647 - val_acc: 0.9798\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 86us/step - loss: 0.0599 - acc: 0.9822 - val_loss: 0.0569 - val_acc: 0.9819\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 85us/step - loss: 0.0439 - acc: 0.9864 - val_loss: 0.0481 - val_acc: 0.9862\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 86us/step - loss: 0.0366 - acc: 0.9883 - val_loss: 0.0451 - val_acc: 0.9871\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 84us/step - loss: 0.0290 - acc: 0.9913 - val_loss: 0.0414 - val_acc: 0.9898\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 3s 86us/step - loss: 0.0245 - acc: 0.9923 - val_loss: 0.0477 - val_acc: 0.9881\n",
      "Epoch 8/10\n",
      "37800/37800 [==============================] - 3s 83us/step - loss: 0.0209 - acc: 0.9932 - val_loss: 0.0400 - val_acc: 0.9898\n",
      "Epoch 00008: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 13s 340us/step - loss: 0.3353 - acc: 0.8970 - val_loss: 0.1045 - val_acc: 0.9683\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 87us/step - loss: 0.0906 - acc: 0.9723 - val_loss: 0.0720 - val_acc: 0.9769\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 86us/step - loss: 0.0630 - acc: 0.9813 - val_loss: 0.0501 - val_acc: 0.9860\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 85us/step - loss: 0.0493 - acc: 0.9853 - val_loss: 0.0494 - val_acc: 0.9845\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 86us/step - loss: 0.0362 - acc: 0.9885 - val_loss: 0.0439 - val_acc: 0.9871\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 85us/step - loss: 0.0302 - acc: 0.9901 - val_loss: 0.0509 - val_acc: 0.9871\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 3s 84us/step - loss: 0.0253 - acc: 0.9915 - val_loss: 0.0509 - val_acc: 0.9874\n",
      "Epoch 00007: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 13s 343us/step - loss: 0.3327 - acc: 0.8975 - val_loss: 0.0940 - val_acc: 0.9729\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 88us/step - loss: 0.0880 - acc: 0.9725 - val_loss: 0.0658 - val_acc: 0.9798\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 87us/step - loss: 0.0597 - acc: 0.9818 - val_loss: 0.0661 - val_acc: 0.9795\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37800/37800 [==============================] - 3s 86us/step - loss: 0.0448 - acc: 0.9873 - val_loss: 0.0473 - val_acc: 0.9864\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 85us/step - loss: 0.0373 - acc: 0.9888 - val_loss: 0.0465 - val_acc: 0.9867\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 86us/step - loss: 0.0287 - acc: 0.9911 - val_loss: 0.0398 - val_acc: 0.9898\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 3s 85us/step - loss: 0.0244 - acc: 0.9926 - val_loss: 0.0425 - val_acc: 0.9883\n",
      "Epoch 8/10\n",
      "37800/37800 [==============================] - 3s 86us/step - loss: 0.0210 - acc: 0.9929 - val_loss: 0.0448 - val_acc: 0.9864\n",
      "Epoch 00008: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 13s 344us/step - loss: 0.3458 - acc: 0.8907 - val_loss: 0.0918 - val_acc: 0.9710\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 87us/step - loss: 0.0908 - acc: 0.9722 - val_loss: 0.0609 - val_acc: 0.9821\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 86us/step - loss: 0.0590 - acc: 0.9814 - val_loss: 0.0524 - val_acc: 0.9845\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 86us/step - loss: 0.0443 - acc: 0.9862 - val_loss: 0.0487 - val_acc: 0.9862\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 86us/step - loss: 0.0369 - acc: 0.9890 - val_loss: 0.0465 - val_acc: 0.9867\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 86us/step - loss: 0.0328 - acc: 0.9901 - val_loss: 0.0483 - val_acc: 0.9857\n",
      "Epoch 00006: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 13s 353us/step - loss: 0.3373 - acc: 0.8957 - val_loss: 0.1063 - val_acc: 0.9695\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 87us/step - loss: 0.0956 - acc: 0.9715 - val_loss: 0.0649 - val_acc: 0.9807\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 85us/step - loss: 0.0649 - acc: 0.9803 - val_loss: 0.0662 - val_acc: 0.9790\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 88us/step - loss: 0.0524 - acc: 0.9839 - val_loss: 0.0494 - val_acc: 0.9843\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 86us/step - loss: 0.0407 - acc: 0.9871 - val_loss: 0.0501 - val_acc: 0.9850\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 84us/step - loss: 0.0345 - acc: 0.9896 - val_loss: 0.0428 - val_acc: 0.9874\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 3s 86us/step - loss: 0.0261 - acc: 0.9925 - val_loss: 0.0473 - val_acc: 0.9867\n",
      "Epoch 8/10\n",
      "37800/37800 [==============================] - 3s 85us/step - loss: 0.0223 - acc: 0.9931 - val_loss: 0.0511 - val_acc: 0.9874\n",
      "Epoch 00008: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 13s 350us/step - loss: 0.3733 - acc: 0.8817 - val_loss: 0.0924 - val_acc: 0.9695\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 86us/step - loss: 0.0843 - acc: 0.9739 - val_loss: 0.0655 - val_acc: 0.9807\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 85us/step - loss: 0.0568 - acc: 0.9822 - val_loss: 0.0509 - val_acc: 0.9850\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 86us/step - loss: 0.0419 - acc: 0.9873 - val_loss: 0.0524 - val_acc: 0.9857\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 87us/step - loss: 0.0349 - acc: 0.9889 - val_loss: 0.0556 - val_acc: 0.9855\n",
      "Epoch 00005: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 13s 353us/step - loss: 0.3821 - acc: 0.8851 - val_loss: 0.0986 - val_acc: 0.9690\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 92us/step - loss: 0.0883 - acc: 0.9726 - val_loss: 0.0743 - val_acc: 0.9771\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 90us/step - loss: 0.0600 - acc: 0.9813 - val_loss: 0.0525 - val_acc: 0.9843\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 86us/step - loss: 0.0471 - acc: 0.9848 - val_loss: 0.0594 - val_acc: 0.9824\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 85us/step - loss: 0.0380 - acc: 0.9881 - val_loss: 0.0399 - val_acc: 0.9888\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 87us/step - loss: 0.0302 - acc: 0.9908 - val_loss: 0.0450 - val_acc: 0.9888\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 3s 85us/step - loss: 0.0273 - acc: 0.9910 - val_loss: 0.0393 - val_acc: 0.9886\n",
      "Epoch 00007: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 13s 331us/step - loss: 0.3434 - acc: 0.8979 - val_loss: 0.0994 - val_acc: 0.9683\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 86us/step - loss: 0.0856 - acc: 0.9742 - val_loss: 0.0601 - val_acc: 0.9807\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 85us/step - loss: 0.0591 - acc: 0.9816 - val_loss: 0.0530 - val_acc: 0.9848\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 84us/step - loss: 0.0438 - acc: 0.9863 - val_loss: 0.0497 - val_acc: 0.9850\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 84us/step - loss: 0.0348 - acc: 0.9891 - val_loss: 0.0469 - val_acc: 0.9838\n",
      "Epoch 00005: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 13s 355us/step - loss: 0.3884 - acc: 0.8798 - val_loss: 0.0927 - val_acc: 0.9705\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 85us/step - loss: 0.0917 - acc: 0.9721 - val_loss: 0.0585 - val_acc: 0.9821\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 85us/step - loss: 0.0622 - acc: 0.9813 - val_loss: 0.0530 - val_acc: 0.9826\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 84us/step - loss: 0.0490 - acc: 0.9853 - val_loss: 0.0395 - val_acc: 0.9886\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 85us/step - loss: 0.0369 - acc: 0.9884 - val_loss: 0.0414 - val_acc: 0.9879\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 84us/step - loss: 0.0295 - acc: 0.9906 - val_loss: 0.0400 - val_acc: 0.9876\n",
      "Epoch 00006: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 13s 334us/step - loss: 0.3510 - acc: 0.8917 - val_loss: 0.0910 - val_acc: 0.9683\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 92us/step - loss: 0.0914 - acc: 0.9720 - val_loss: 0.0654 - val_acc: 0.9807\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 89us/step - loss: 0.0629 - acc: 0.9807 - val_loss: 0.0640 - val_acc: 0.9805\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 86us/step - loss: 0.0474 - acc: 0.9852 - val_loss: 0.0511 - val_acc: 0.9850\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 86us/step - loss: 0.0359 - acc: 0.9888 - val_loss: 0.0427 - val_acc: 0.9857\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 85us/step - loss: 0.0308 - acc: 0.9904 - val_loss: 0.0507 - val_acc: 0.9862\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 3s 84us/step - loss: 0.0271 - acc: 0.9908 - val_loss: 0.0511 - val_acc: 0.9867\n",
      "Epoch 8/10\n",
      "37800/37800 [==============================] - 3s 84us/step - loss: 0.0216 - acc: 0.9930 - val_loss: 0.0496 - val_acc: 0.9871\n",
      "Epoch 00008: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 13s 343us/step - loss: 0.3492 - acc: 0.8895 - val_loss: 0.0931 - val_acc: 0.9710\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 89us/step - loss: 0.0928 - acc: 0.9721 - val_loss: 0.0750 - val_acc: 0.9767\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 88us/step - loss: 0.0625 - acc: 0.9815 - val_loss: 0.0622 - val_acc: 0.9812\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 90us/step - loss: 0.0463 - acc: 0.9859 - val_loss: 0.0415 - val_acc: 0.9881\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 89us/step - loss: 0.0355 - acc: 0.9888 - val_loss: 0.0459 - val_acc: 0.9867\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37800/37800 [==============================] - 3s 89us/step - loss: 0.0290 - acc: 0.9906 - val_loss: 0.0433 - val_acc: 0.9871\n",
      "Epoch 00006: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 13s 355us/step - loss: 0.3602 - acc: 0.8887 - val_loss: 0.0987 - val_acc: 0.9686\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 92us/step - loss: 0.0888 - acc: 0.9729 - val_loss: 0.0568 - val_acc: 0.9819\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 4s 94us/step - loss: 0.0591 - acc: 0.9816 - val_loss: 0.0511 - val_acc: 0.9826\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 92us/step - loss: 0.0476 - acc: 0.9852 - val_loss: 0.0501 - val_acc: 0.9852\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 90us/step - loss: 0.0356 - acc: 0.9890 - val_loss: 0.0405 - val_acc: 0.9869\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 4s 94us/step - loss: 0.0315 - acc: 0.9901 - val_loss: 0.0443 - val_acc: 0.9874\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 3s 90us/step - loss: 0.0262 - acc: 0.9919 - val_loss: 0.0369 - val_acc: 0.9890\n",
      "Epoch 8/10\n",
      "37800/37800 [==============================] - 3s 90us/step - loss: 0.0218 - acc: 0.9934 - val_loss: 0.0429 - val_acc: 0.9890\n",
      "Epoch 9/10\n",
      "37800/37800 [==============================] - 4s 93us/step - loss: 0.0177 - acc: 0.9941 - val_loss: 0.0440 - val_acc: 0.9879\n",
      "Epoch 00009: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 13s 346us/step - loss: 0.3548 - acc: 0.8928 - val_loss: 0.1096 - val_acc: 0.9676\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 3s 91us/step - loss: 0.0943 - acc: 0.9715 - val_loss: 0.0662 - val_acc: 0.9793\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 3s 88us/step - loss: 0.0619 - acc: 0.9815 - val_loss: 0.0591 - val_acc: 0.9838\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 3s 88us/step - loss: 0.0492 - acc: 0.9853 - val_loss: 0.0569 - val_acc: 0.9829\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 3s 88us/step - loss: 0.0396 - acc: 0.9874 - val_loss: 0.0431 - val_acc: 0.9864\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 3s 88us/step - loss: 0.0322 - acc: 0.9899 - val_loss: 0.0463 - val_acc: 0.9867\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 3s 88us/step - loss: 0.0277 - acc: 0.9914 - val_loss: 0.0388 - val_acc: 0.9890\n",
      "Epoch 8/10\n",
      "37800/37800 [==============================] - 3s 88us/step - loss: 0.0213 - acc: 0.9933 - val_loss: 0.0521 - val_acc: 0.9862\n",
      "Epoch 9/10\n",
      "37800/37800 [==============================] - 3s 86us/step - loss: 0.0212 - acc: 0.9927 - val_loss: 0.0501 - val_acc: 0.9871\n",
      "Epoch 00009: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 13s 353us/step - loss: 0.3435 - acc: 0.8940 - val_loss: 0.0955 - val_acc: 0.9712\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 4s 96us/step - loss: 0.0898 - acc: 0.9726 - val_loss: 0.0637 - val_acc: 0.9798\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 4s 97us/step - loss: 0.0619 - acc: 0.9810 - val_loss: 0.0579 - val_acc: 0.9807\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 4s 95us/step - loss: 0.0451 - acc: 0.9865 - val_loss: 0.0478 - val_acc: 0.9860\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 4s 95us/step - loss: 0.0368 - acc: 0.9887 - val_loss: 0.0508 - val_acc: 0.9848\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 4s 94us/step - loss: 0.0297 - acc: 0.9902 - val_loss: 0.0480 - val_acc: 0.9874\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 4s 93us/step - loss: 0.0255 - acc: 0.9918 - val_loss: 0.0432 - val_acc: 0.9900\n",
      "Epoch 8/10\n",
      "37800/37800 [==============================] - 4s 94us/step - loss: 0.0218 - acc: 0.9927 - val_loss: 0.0454 - val_acc: 0.9879\n",
      "Epoch 9/10\n",
      "37800/37800 [==============================] - 4s 95us/step - loss: 0.0176 - acc: 0.9945 - val_loss: 0.0443 - val_acc: 0.9888\n",
      "Epoch 00009: early stopping\n",
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/10\n",
      "37800/37800 [==============================] - 14s 362us/step - loss: 0.3261 - acc: 0.9023 - val_loss: 0.0930 - val_acc: 0.9695\n",
      "Epoch 2/10\n",
      "37800/37800 [==============================] - 4s 97us/step - loss: 0.0858 - acc: 0.9736 - val_loss: 0.0589 - val_acc: 0.9829\n",
      "Epoch 3/10\n",
      "37800/37800 [==============================] - 4s 96us/step - loss: 0.0597 - acc: 0.9821 - val_loss: 0.0518 - val_acc: 0.9843\n",
      "Epoch 4/10\n",
      "37800/37800 [==============================] - 4s 96us/step - loss: 0.0420 - acc: 0.9868 - val_loss: 0.0530 - val_acc: 0.9850\n",
      "Epoch 5/10\n",
      "37800/37800 [==============================] - 4s 95us/step - loss: 0.0341 - acc: 0.9891 - val_loss: 0.0446 - val_acc: 0.9862\n",
      "Epoch 6/10\n",
      "37800/37800 [==============================] - 4s 96us/step - loss: 0.0272 - acc: 0.9910 - val_loss: 0.0459 - val_acc: 0.9883\n",
      "Epoch 7/10\n",
      "37800/37800 [==============================] - 4s 94us/step - loss: 0.0260 - acc: 0.9913 - val_loss: 0.0412 - val_acc: 0.9879\n",
      "Epoch 8/10\n",
      "37800/37800 [==============================] - 4s 94us/step - loss: 0.0226 - acc: 0.9928 - val_loss: 0.0494 - val_acc: 0.9881\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "Y_test_pred = np.ndarray((28000,100))\n",
    "for run in range(100):\n",
    "    model = cnn3_model()\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, callbacks=[EarlyStopping(monitor='val_acc', min_delta=0.001, patience=2, verbose=1, mode='auto')])\n",
    "    Y_test_pred[:,run] = model.predict_classes(X_subm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_ensemb = stats.mode(Y_test_pred, axis=1)[0].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm = pd.DataFrame({\"ImageId\": np.arange(1, m+1), \"Label\": Y_ensemb.flatten()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm.to_csv(\"subm_ensemble100.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6886    4    1    0    2    0    5    1    2    2]\n",
      " [   1 7862    4    0    1    0    1    7    1    0]\n",
      " [   4    4 6951    3    2    0    2    9   13    2]\n",
      " [   1    3   10 7094    0    9    0    8   12    4]\n",
      " [   2    6    0    0 6797    0    2    5    2   10]\n",
      " [   2    2    1   11    1 6260   21    2   10    3]\n",
      " [   5    7    0    0    4    1 6859    0    0    0]\n",
      " [   1   19   14    1    7    1    0 7238    4    8]\n",
      " [   4   13    3    6    3    7   12    1 6771    5]\n",
      " [   6    6    0    5   23    7    0   12   10 6889]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9943857142857143"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test_true, Y_ensemb))\n",
    "accuracy_score(my, Y_ensemb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6888    0    0    1    2    1    3    1    5    2]\n",
      " [   1 7844   11    0    1    1    3   13    2    1]\n",
      " [   4    3 6964    3    2    0    1    5    6    2]\n",
      " [   1    1   15 7100    0    8    0    8    5    3]\n",
      " [   3    7    2    0 6796    0    2    3    2    9]\n",
      " [   3    2    1   11    1 6271   11    0    9    4]\n",
      " [   9    6    0    1    4    5 6849    0    2    0]\n",
      " [   1    8   14    4    5    2    0 7249    3    7]\n",
      " [   4    7    7    5    7    9    7    1 6768   10]\n",
      " [   7    4    0    5   15    8    1   13    7 6898]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9946714285714285"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test_true, Y_ensemb))\n",
    "accuracy_score(my, Y_ensemb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6891    0    0    0    2    1    2    1    4    2]\n",
      " [   1 7850    9    1    2    2    2    7    3    0]\n",
      " [   3    4 6957    4    1    0    1   11    7    2]\n",
      " [   0    0    9 7106    0   11    0    7    4    4]\n",
      " [   3    7    0    0 6785    0    2    4    3   20]\n",
      " [   3    2    1    8    0 6272   16    0    9    2]\n",
      " [   8    3    1    0    4    3 6851    0    6    0]\n",
      " [   1   10    9    3    5    2    0 7251    5    7]\n",
      " [   4    4    8    5    4    8    4    3 6781    4]\n",
      " [   5    3    0    5   11    7    0    9   11 6907]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9950142857142857"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test_true, Y_ensemb))\n",
    "accuracy_score(my, Y_ensemb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6887    2    1    0    1    1    6    1    2    2]\n",
      " [   1 7854    7    0    2    2    2    7    2    0]\n",
      " [   4    3 6960    4    1    0    1   10    5    2]\n",
      " [   0    2    9 7105    0   10    0    8    3    4]\n",
      " [   2    5    0    0 6794    0    5    3    2   13]\n",
      " [   4    2    1    9    0 6271   16    0    6    4]\n",
      " [   7    5    0    0    4    2 6857    0    1    0]\n",
      " [   1    9    7    3    4    2    0 7258    4    5]\n",
      " [   4    8    7    5    5    8    9    4 6767    8]\n",
      " [   6    3    0    4   15    5    1    9    5 6910]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9951857142857143"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test_true, Y_ensemb))\n",
    "accuracy_score(my, Y_ensemb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(Y_test_true, Y_ensemb))\n",
    "accuracy_score(my, Y_ensemb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
